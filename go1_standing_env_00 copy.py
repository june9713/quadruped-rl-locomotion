#!/usr/bin/env python3
"""
Go1 2ì¡± ë³´í–‰ (Standing/Bipedal Walking) í™˜ê²½
"""

import numpy as np
import mujoco
from go1_mujoco_env import Go1MujocoEnv
import math
from collections import deque

# visual_train.pyì—ì„œ importí•  ìˆ˜ ìˆë„ë¡ í™˜ê²½ ì´ë¦„ ì¶”ê°€
__all__ = ['Go1StandingEnv', 'GradualStandingEnv', 'StandingReward']


class StandingReward:
    """2ì¡± ë³´í–‰ì„ ìœ„í•œ ë³´ìƒ í•¨ìˆ˜"""

    def __init__(self):
        # ë³´ìƒ ê°€ì¤‘ì¹˜ë“¤
        self.weights = {
            'upright': 15.0,        # ë˜‘ë°”ë¡œ ì„œìˆê¸°
            'height': 10.0,         # ì ì ˆí•œ ë†’ì´ ìœ ì§€
            'balance': 8.0,         # ê· í˜• ìœ ì§€
            'foot_contact': 5.0,    # ë’·ë°œë¡œë§Œ ì„œìˆê¸°
            'forward_vel': 3.0,     # ì „ì§„ ì†ë„
            'lateral_stability': 4.0, # ì¢Œìš° ì•ˆì •ì„±
            'energy': -0.05,        # ì—ë„ˆì§€ íš¨ìœ¨
            'joint_limit': -5.0,    # ê´€ì ˆ í•œê³„ í˜ë„í‹°
            'symmetry': 3.0,        # ì¢Œìš° ëŒ€ì¹­ì„±
            'smooth_motion': 2.0    # ë¶€ë“œëŸ¬ìš´ ë™ì‘
        }

    def compute_reward(self, model, data):
        """2ì¡± ë³´í–‰ ë³´ìƒ ê³„ì‚°"""
        total_reward = 0.0
        reward_info = {}

        # 1. ë˜‘ë°”ë¡œ ì„œìˆê¸° ë³´ìƒ
        trunk_quat = data.qpos[3:7]
        trunk_rotation_matrix = self._quat_to_rotmat(trunk_quat)
        up_vector = trunk_rotation_matrix[:, 2]  # zì¶• ë°©í–¥

        # ëª¸ì²´ê°€ ë˜‘ë°”ë¡œ ì„œìˆì–´ì•¼ í•¨
        upright_reward = up_vector[2]  # z ì„±ë¶„ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
        upright_reward = max(0, upright_reward)
        total_reward += self.weights['upright'] * upright_reward
        reward_info['upright'] = upright_reward

        # 2. ë†’ì´ ë³´ìƒ
        trunk_height = data.qpos[2]
        target_height = 0.5  # 2ì¡± ë³´í–‰ì‹œ ëª©í‘œ ë†’ì´
        height_error = abs(trunk_height - target_height)
        height_reward = np.exp(-10 * height_error)
        total_reward += self.weights['height'] * height_reward
        reward_info['height'] = height_reward

        # 3. ë°œ ì ‘ì´‰ ë³´ìƒ (ë’·ë°œë¡œë§Œ ì„œìˆì–´ì•¼ í•¨)
        foot_contacts = self._get_foot_contacts(model, data)
        # ì•ë°œ(FR, FL)ì€ ë•…ì— ë‹¿ìœ¼ë©´ ì•ˆë¨, ë’·ë°œ(RR, RL)ì€ ë‹¿ì•„ì•¼ í•¨
        front_foot_penalty = foot_contacts[0] + foot_contacts[1]  # FR + FL
        rear_foot_reward = foot_contacts[2] + foot_contacts[3]    # RR + RL

        foot_reward = rear_foot_reward - 2 * front_foot_penalty
        total_reward += self.weights['foot_contact'] * foot_reward
        reward_info['foot_contact'] = foot_reward

        # 4. ê· í˜• ë³´ìƒ
        trunk_vel = data.qvel[:3]
        trunk_angular_vel = data.qvel[3:6]

        # ë„ˆë¬´ ë¹ ë¥´ê²Œ ì›€ì§ì´ì§€ ì•Šì•„ì•¼ í•¨
        linear_stability = np.exp(-2 * np.linalg.norm(trunk_vel[1:]))  # y,z ì†ë„ ì œí•œ
        angular_stability = np.exp(-3 * np.linalg.norm(trunk_angular_vel))

        balance_reward = linear_stability * angular_stability
        total_reward += self.weights['balance'] * balance_reward
        reward_info['balance'] = balance_reward

        # 5. ì „ì§„ ì†ë„ ë³´ìƒ (ì ë‹¹í•œ ì†ë„ë¡œ ì „ì§„)
        forward_vel = trunk_vel[0]  # x ë°©í–¥ ì†ë„
        target_vel = 0.3  # ëª©í‘œ ì „ì§„ ì†ë„

        # ë„ˆë¬´ ë¹ ë¥´ê±°ë‚˜ ë’¤ë¡œ ê°€ë©´ í˜ë„í‹°
        if forward_vel < 0:
            vel_reward = 0
        elif forward_vel > target_vel * 2:
            vel_reward = np.exp(-5 * (forward_vel - target_vel * 2))
        else:
            vel_reward = forward_vel / target_vel

        total_reward += self.weights['forward_vel'] * vel_reward
        reward_info['forward_vel'] = vel_reward

        # 6. ì¢Œìš° ì•ˆì •ì„± (ì˜†ìœ¼ë¡œ ê¸°ìš¸ì§€ ì•Šê¸°)
        roll_angle = np.arctan2(up_vector[1], up_vector[2])
        lateral_reward = np.exp(-10 * abs(roll_angle))
        total_reward += self.weights['lateral_stability'] * lateral_reward
        reward_info['lateral_stability'] = lateral_reward

        # 7. ì—ë„ˆì§€ íš¨ìœ¨ì„±
        motor_efforts = np.sum(np.square(data.ctrl))
        energy_penalty = motor_efforts
        total_reward += self.weights['energy'] * energy_penalty
        reward_info['energy'] = -energy_penalty

        # 8. ê´€ì ˆ í•œê³„ í˜ë„í‹°
        joint_limit_penalty = self._compute_joint_limit_penalty(model, data)
        total_reward += self.weights['joint_limit'] * joint_limit_penalty
        reward_info['joint_limit'] = -joint_limit_penalty

        # 9. ì¢Œìš° ëŒ€ì¹­ì„± (2ì¡± ë³´í–‰ì˜ ì¤‘ìš”í•œ ìš”ì†Œ)
        symmetry_reward = self._compute_symmetry_reward(data)
        total_reward += self.weights['symmetry'] * symmetry_reward
        reward_info['symmetry'] = symmetry_reward

        # 10. ë¶€ë“œëŸ¬ìš´ ë™ì‘
        if hasattr(self, '_last_action'):
            action_diff = np.sum(np.square(data.ctrl - self._last_action))
            smooth_reward = np.exp(-0.1 * action_diff)
            total_reward += self.weights['smooth_motion'] * smooth_reward
            reward_info['smooth_motion'] = smooth_reward

        self._last_action = data.ctrl.copy()

        return total_reward, reward_info

    def _quat_to_rotmat(self, quat):
        """Quaternionì„ rotation matrixë¡œ ë³€í™˜"""
        w, x, y, z = quat
        return np.array([
            [1 - 2 * y * y - 2 * z * z, 2 * x * y - 2 * w * z, 2 * x * z + 2 * w * y],
            [2 * x * y + 2 * w * z, 1 - 2 * x * x - 2 * z * z, 2 * y * z - 2 * w * x],
            [2 * x * z - 2 * w * y, 2 * y * z + 2 * w * x, 1 - 2 * x * x - 2 * y * y]
        ])

    def _get_foot_contacts(self, model, data):
        """ë°œ ì ‘ì´‰ ê°ì§€"""
        foot_names = ["FR", "FL", "RR", "RL"]
        contacts = []

        for foot_name in foot_names:
            try:
                foot_geom_id = model.geom(foot_name).id
                contact = False

                for i in range(data.ncon):
                    contact_geom1 = data.contact[i].geom1
                    contact_geom2 = data.contact[i].geom2

                    if contact_geom1 == foot_geom_id or contact_geom2 == foot_geom_id:
                        # ì ‘ì´‰ë ¥ í™•ì¸
                        contact_force = np.linalg.norm(data.contact[i].force)
                        if contact_force > 0.1:  # ì˜ë¯¸ìˆëŠ” ì ‘ì´‰
                            contact = True
                            break

                contacts.append(1.0 if contact else 0.0)
            except:
                contacts.append(0.0)

        return contacts

    def _compute_joint_limit_penalty(self, model, data):
        """ê´€ì ˆ í•œê³„ í˜ë„í‹° ê³„ì‚°"""
        joint_pos = data.qpos[7:]  # ê´€ì ˆ ìœ„ì¹˜
        joint_ranges = model.jnt_range[1:]  # ì²« ë²ˆì§¸ëŠ” root joint

        penalty = 0.0
        for i, pos in enumerate(joint_pos):
            if pos < joint_ranges[i, 0]:
                penalty += (joint_ranges[i, 0] - pos) ** 2
            elif pos > joint_ranges[i, 1]:
                penalty += (pos - joint_ranges[i, 1]) ** 2

        return penalty

    def _compute_symmetry_reward(self, data):
        """ì¢Œìš° ëŒ€ì¹­ì„± ë³´ìƒ"""
        # ê´€ì ˆ ìœ„ì¹˜ (FR, FL, RR, RL ìˆœì„œ)
        joint_pos = data.qpos[7:19]

        # ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ì˜ ì°¨ì´
        # FR(0-2) vs FL(3-5), RR(6-8) vs RL(9-11)
        front_diff = np.sum(np.abs(joint_pos[0:3] - joint_pos[3:6]))
        rear_diff = np.sum(np.abs(joint_pos[6:9] - joint_pos[9:12]))

        symmetry_error = front_diff + rear_diff
        symmetry_reward = np.exp(-2 * symmetry_error)

        return symmetry_reward


class EnhancedStableStandingReward:
    """
    ê°œì„ ëœ 2ì¡± ë³´í–‰ ë³´ìƒ í•¨ìˆ˜ - ë™ì  ì•ˆì •ì„±ê³¼ ë¬¼ë¦¬ì  ì œì•½ ê°•í™”
    """
    def __init__(self):
        self.scale = 10.0
        self.target_height = 0.5
        self.target_vel = 0.3
        self.rear_feet = ["RR", "RL"]
        self.front_feet = ["FR", "FL"]

        # í•™ìŠµ ì§„í–‰ë„ ì¶”ì 
        self.num_timesteps = 0
        self.success_buffer = deque(maxlen=100)
        self.joint_history = deque(maxlen=50)

        # ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ íŒŒë¼ë¯¸í„° (ìˆ˜ì •ë¨)
        self.curriculum_stage = 0
        self.height_tolerance = 0.25      # ê¸°ì¡´ 0.2 -> 0.25 (ì´ˆê¸° í—ˆìš© ì˜¤ì°¨ ì™„í™”)
        self.upright_threshold = 0.65   # ê¸°ì¡´ 0.7 -> 0.65 (ì´ˆê¸° í—ˆìš© ì˜¤ì°¨ ì™„í™”)

        # ì´ì „ ìƒíƒœ ì €ì¥
        self._prev_a = None
        self.prev_energy = None

    def compute_reward(self, model, data):
        """ì „ì²´ ë³´ìƒ ê³„ì‚°"""
        r = {}

        # 1) ìì„¸ ì§ë¦½ë„ (ê°œì„ ëœ ë²„ì „)
        up_z = self._quat_to_rotmat(data.qpos[3:7])[:, 2][2]
        # ê¸°ìš¸ê¸°ì— ëŒ€í•´ ë” ë¯¼ê°í•œ ë°˜ì‘
        angle_from_vertical = np.arccos(np.clip(up_z, -1, 1))
        r["upright"] = np.exp(-5 * angle_from_vertical ** 2)

        # 2) ë†’ì´ (ì»¤ë¦¬í˜ëŸ¼ ì ìš©)
        h = data.qpos[2]
        current_tolerance = self.height_tolerance * (0.5 + 0.5 * np.exp(-self.curriculum_stage))
        r["height"] = np.exp(-((h - self.target_height) / current_tolerance) ** 2)

        # 3) ë°œ ì ‘ì´‰
        contacts = self._get_foot_contacts(model, data)
        if len(contacts) == 4:
            rear = (contacts[2] + contacts[3]) / 2.0
            front = (contacts[0] + contacts[1]) / 2.0
        else:
            rear = front = 0.0
        r["feet"] = rear - front

        # 4) ì „ì§„ ì†ë„
        v = data.qvel[0]
        r["forward_vel"] = np.exp(-((v - self.target_vel) / 0.15) ** 2)

        # 5) ì¢Œìš° ì†ë„ ì–µì œ (ìƒˆë¡œ ì¶”ê°€)
        v_lat = np.linalg.norm(data.qvel[1:3])
        r["lateral_vel"] = np.exp(-(v_lat / 0.3) ** 2)

        # 6) ê· í˜• (ê°œì„ )
        ang_v = np.linalg.norm(data.qvel[3:6])
        r["stab_ang"] = np.exp(-(ang_v / 5.0) ** 2)

        # 7) COP ì•ˆì •ì„± (ìƒˆë¡œ ì¶”ê°€)
        r["cop_stab"] = self._cop_stability(model, data)

        # 8) ZMP ì•ˆì •ì„± (ìƒˆë¡œ ì¶”ê°€)
        r["zmp_stab"] = self._zmp_stability(model, data)

        # 9) ë°œ ì••ë ¥ ë¶„í¬ (ìƒˆë¡œ ì¶”ê°€)
        r["pressure_dist"] = self._foot_pressure_distribution(model, data)

        # 10) ì£¼ê¸°ì  ì›€ì§ì„ (ìƒˆë¡œ ì¶”ê°€)
        r["gait_period"] = self._gait_periodicity_reward(data)

        # 11) ì—ë„ˆì§€ í˜ë„í‹° (ì ì‘í˜•)
        effort = np.mean(np.square(data.ctrl))
        progress = min(1.0, self.num_timesteps / 1e6)
        energy_weight = 0.25 + 0.75 * progress
        r["energy"] = -energy_weight * math.tanh(effort / 50.0)

        # 12) ê´€ì ˆ í•œê³„ (ê°œì„ )
        joint_penalty = self._joint_limit_violation_smooth(model, data)
        r["joint"] = -math.tanh(joint_penalty / 5.0)

        # 13) ë¶€ë“œëŸ¬ìš´ ë™ì‘
        if self._prev_a is not None:
            diff = np.mean(np.square(data.ctrl - self._prev_a))
            r["smooth"] = math.exp(-(diff / 0.2) ** 2)
        else:
            r["smooth"] = 1.0
        self._prev_a = data.ctrl.copy()

        # 14) ëŒ€ì¹­ì„±
        r["symmetry"] = self._compute_symmetry_reward(data)

        # 15) ì˜ˆì¸¡ ì•ˆì •ì„± (ìƒˆë¡œ ì¶”ê°€)
        r["predictive"] = self._predictive_stability(model, data)

        # 16) ë¬¼ë¦¬ì  ì œì•½ (ìƒˆë¡œ ì¶”ê°€)
        phys_reward, _ = self._physical_constraints_reward(model, data)
        r["physics"] = phys_reward

        # ì´í•© ê³„ì‚°
        total = self.scale * sum(r.values()) / len(r)

        # í•™ìŠµ ì§„í–‰ë„ ì—…ë°ì´íŠ¸
        self.num_timesteps += 1
        self._update_curriculum(r)

        return total, r

    def _update_curriculum(self, rewards):
        """ì»¤ë¦¬í˜ëŸ¼ ë‹¨ê³„ ì—…ë°ì´íŠ¸ (ìˆ˜ì •ë¨)"""
        # ì„±ê³µ íŒë‹¨ (ë†’ì´ ìœ ì§€ & ì§ë¦½ & ë°œ ì ‘ì´‰)
        # ì´ˆê¸° ì„±ê³µ ì¡°ê±´ì„ ì•½ê°„ ì™„í™”í•˜ê³ , ë‹¨ê³„ë³„ë¡œ ì—„ê²©í•˜ê²Œ ì¡°ì •
        height_success_threshold = 0.65 + 0.05 * self.curriculum_stage
        upright_success_threshold = 0.75 + 0.05 * self.curriculum_stage

        success = (rewards.get("height", 0) > height_success_threshold and
                   rewards.get("upright", 0) > upright_success_threshold and
                   rewards.get("feet", 0) > 0.5)

        self.success_buffer.append(success)

        # ì„±ê³µë¥ ì´ 80% ì´ìƒì´ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        if len(self.success_buffer) >= 50:
            success_rate = sum(self.success_buffer) / len(self.success_buffer)
            if success_rate > 0.8 and self.curriculum_stage < 5:
                self.curriculum_stage += 1
                # ê°ì†Œí­ ì™„í™”
                self.height_tolerance = max(0.1, self.height_tolerance * 0.85)
                self.upright_threshold = min(0.9, self.upright_threshold + 0.05)
                print(f"ğŸ“ ì»¤ë¦¬í˜ëŸ¼ ì§„í–‰: Stage {self.curriculum_stage}")

    def _cop_stability(self, model, data):
        """Center of Pressure ì•ˆì •ì„±"""
        try:
            # ê°„ë‹¨í•œ ê·¼ì‚¬: ë’·ë°œ ì ‘ì´‰ì ë“¤ì˜ ì¤‘ì‹¬
            rear_contacts = []
            for foot_name in self.rear_feet:
                foot_id = model.site(foot_name).id
                foot_pos = data.site_xpos[foot_id][:2]  # x, y ì¢Œí‘œ
                rear_contacts.append(foot_pos)

            if len(rear_contacts) >= 2:
                cop = np.mean(rear_contacts, axis=0)
                # ì§€ì§€ ë‹¤ê°í˜• ë‚´ë¶€ íŒì • (ê°„ë‹¨í™”)
                center = np.mean(rear_contacts, axis=0)
                dist = np.linalg.norm(cop - center)
                max_dist = np.linalg.norm(rear_contacts[0] - rear_contacts[1]) / 2
                return np.exp(-5 * (dist / max_dist) ** 2)
            return 0.5
        except:
            return 0.5

    def _zmp_stability(self, model, data):
        """Zero Moment Point ì•ˆì •ì„±"""
        try:
            # ê°„ë‹¨í•œ ZMP ê·¼ì‚¬
            com_pos = data.qpos[:3]
            com_vel = data.qvel[:3]
            gravity = model.opt.gravity[2]

            # ZMP x = COM_x - (COM_z / g) * COM_x_accel
            zmp_x = com_pos[0] - (com_pos[2] / abs(gravity)) * com_vel[0]
            zmp_y = com_pos[1] - (com_pos[2] / abs(gravity)) * com_vel[1]

            # ì§€ì§€ ë‹¤ê°í˜•ê³¼ì˜ ê±°ë¦¬
            support_center = np.array([com_pos[0], com_pos[1]])
            zmp_pos = np.array([zmp_x, zmp_y])
            dist = np.linalg.norm(zmp_pos - support_center)

            return np.exp(-3 * dist ** 2)
        except:
            return 0.5

    def _foot_pressure_distribution(self, model, data):
        """ë°œ ì••ë ¥ ë¶„í¬ì˜ ê· ì¼ì„±"""
        try:
            pressures = []
            for i in range(data.ncon):
                for foot_name in self.rear_feet:
                    foot_id = model.geom(foot_name).id
                    if data.contact[i].geom1 == foot_id or data.contact[i].geom2 == foot_id:
                        force = np.linalg.norm(data.contact[i].force)
                        pressures.append(force)

            if len(pressures) >= 2:
                # ì••ë ¥ ë¶„í¬ì˜ ê· ì¼ì„±
                var = np.var(pressures)
                return np.exp(-10 * var / (np.mean(pressures) ** 2 + 1e-6))
            return 0.5
        except:
            return 0.5

    def _gait_periodicity_reward(self, data, window=50):
        """ë³´í–‰ì˜ ì£¼ê¸°ì„±"""
        # ê´€ì ˆ ê°ë„ ê¸°ë¡
        joint_angles = data.qpos[7:19]
        self.joint_history.append(joint_angles.copy())

        if len(self.joint_history) < window:
            return 0.5

        try:
            # ê°„ë‹¨í•œ ì£¼ê¸°ì„± ì¸¡ì •: ìê¸°ìƒê´€
            joint_data = np.array(list(self.joint_history)[-window:])
            mean_data = np.mean(joint_data, axis=0)
            centered = joint_data - mean_data

            # ìê¸°ìƒê´€ ê³„ì‚°
            autocorr = np.correlate(centered[:, 6], centered[:, 6], mode='full')
            autocorr = autocorr[len(autocorr) // 2:]

            # ì£¼ê¸°ì„± ê°•ë„
            if len(autocorr) > 10:
                periodicity = np.max(autocorr[5:20]) / (autocorr[0] + 1e-6)
                return np.clip(periodicity, 0, 1)
            return 0.5
        except:
            return 0.5

    def _predictive_stability(self, model, data, horizon=5):
        """ë¯¸ë˜ ì•ˆì •ì„± ì˜ˆì¸¡"""
        try:
            # í˜„ì¬ ì†ë„ë¡œ horizon ìŠ¤í… í›„ ìœ„ì¹˜ ì˜ˆì¸¡
            com_pos = data.qpos[:3].copy()
            com_vel = data.qvel[:3].copy()
            dt = model.opt.timestep

            future_pos = com_pos + com_vel * dt * horizon

            # ì˜ˆì¸¡ ìœ„ì¹˜ê°€ ì•ˆì • ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€
            height_ok = 0.3 < future_pos[2] < 0.7
            lateral_ok = np.linalg.norm(future_pos[:2] - com_pos[:2]) < 0.2

            return float(height_ok and lateral_ok)
        except:
            return 0.5

    def _physical_constraints_reward(self, model, data):
        """ë¬¼ë¦¬ì  ì œì•½ ì¤€ìˆ˜"""
        rewards = {}

        try:
            # 1. ê°ìš´ë™ëŸ‰ ë³´ì¡´
            angular_vel = data.qvel[3:6]
            ang_momentum = np.linalg.norm(angular_vel)
            rewards['ang_momentum'] = np.exp(-0.1 * ang_momentum)

            # 2. ì—ë„ˆì§€ ë³´ì¡´
            # ìœ„ì¹˜ ì—ë„ˆì§€ + ìš´ë™ ì—ë„ˆì§€
            height = data.qpos[2]
            vel = np.linalg.norm(data.qvel[:3])
            total_energy = 9.81 * height + 0.5 * vel ** 2

            if self.prev_energy is not None:
                energy_change = abs(total_energy - self.prev_energy)
                rewards['energy_conservation'] = np.exp(-10 * energy_change)
            else:
                rewards['energy_conservation'] = 1.0
            self.prev_energy = total_energy

        except:
            rewards = {'ang_momentum': 0.5, 'energy_conservation': 0.5}

        return np.mean(list(rewards.values())), rewards

    def _joint_limit_violation_smooth(self, model, data):
        """ë¶€ë“œëŸ¬ìš´ ê´€ì ˆ í•œê³„ í˜ë„í‹°"""
        joint_pos = data.qpos[7:]
        joint_ranges = model.jnt_range[1:]

        penalty = 0.0
        margin = 0.1  # ì—¬ìœ  ë§ˆì§„

        for i, pos in enumerate(joint_pos):
            lower, upper = joint_ranges[i]

            # ë¶€ë“œëŸ¬ìš´ í˜ë„í‹° í•¨ìˆ˜
            if pos < lower + margin:
                violation = (lower + margin - pos) / margin
                penalty += 1 / (1 + np.exp(-10 * (violation - 0.5)))
            elif pos > upper - margin:
                violation = (pos - (upper - margin)) / margin
                penalty += 1 / (1 + np.exp(-10 * (violation - 0.5)))

        return penalty

    def _compute_symmetry_reward(self, data):
        """ì¢Œìš° ëŒ€ì¹­ì„± ë³´ìƒ"""
        joint_pos = data.qpos[7:19]

        # ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ì˜ ì°¨ì´
        front_diff = np.sum(np.abs(joint_pos[0:3] - joint_pos[3:6]))
        rear_diff = np.sum(np.abs(joint_pos[6:9] - joint_pos[9:12]))

        symmetry_error = front_diff + rear_diff
        return np.exp(-2 * symmetry_error)

    # Helper methods
    def _quat_to_rotmat(self, quat):
        """Quaternionì„ rotation matrixë¡œ ë³€í™˜"""
        w, x, y, z = quat
        return np.array([
            [1 - 2 * y * y - 2 * z * z, 2 * x * y - 2 * w * z, 2 * x * z + 2 * w * y],
            [2 * x * y + 2 * w * z, 1 - 2 * x * x - 2 * z * z, 2 * y * z - 2 * w * x],
            [2 * x * z - 2 * w * y, 2 * y * z + 2 * w * x, 1 - 2 * x * x - 2 * y * y]
        ])

    def _get_foot_contacts(self, model, data):
        """ë°œ ì ‘ì´‰ ê°ì§€"""
        foot_names = ["FR", "FL", "RR", "RL"]
        contacts = []

        for foot_name in foot_names:
            try:
                foot_geom_id = model.geom(foot_name).id
                contact = False

                for i in range(data.ncon):
                    if (data.contact[i].geom1 == foot_geom_id or
                            data.contact[i].geom2 == foot_geom_id):
                        contact_force = np.linalg.norm(data.contact[i].force)
                        if contact_force > 0.1:
                            contact = True
                            break

                contacts.append(1.0 if contact else 0.0)
            except:
                contacts.append(0.0)

        return contacts


class Go1StandingEnv(Go1MujocoEnv):
    """2ì¡± ë³´í–‰ì„ í•™ìŠµí•˜ëŠ” Go1 í™˜ê²½"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.standing_reward = EnhancedStableStandingReward()  # ê°œì„ ëœ ë³´ìƒ í•¨ìˆ˜ ì‚¬ìš©
        self.episode_length = 0
        self.max_episode_length = 1000

        # --- ìˆ˜ì •ë¨: ì¡°ê¸° ì¢…ë£Œ ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì • ---
        self.grace_steps = 30       # ì´ˆê¸° 10 -> 30 ìŠ¤í…ìœ¼ë¡œ ìœ ì˜ˆ ì‹œê°„ ì¦ê°€
        self._post_reset = True     # reset ì§í›„ ìƒíƒœ í”Œë˜ê·¸
        self.consecutive_failures = 0
        self.failure_threshold = 5  # 5 í”„ë ˆì„ ì—°ì†ìœ¼ë¡œ ë¶ˆì•ˆì •í•  ê²½ìš°ì—ë§Œ ì¢…ë£Œ
        # --- ìˆ˜ì • ë ---

        # 2ì¡± ë³´í–‰ì„ ìœ„í•œ ì„¤ì • ë³€ê²½
        self._healthy_z_range = (0.35, 0.65)  # ë” ë†’ì€ ìì„¸
        self._healthy_pitch_range = (-np.deg2rad(15), np.deg2rad(15))  # ì•½ê°„ ê´€ëŒ€í•œ pitch
        self._healthy_roll_range = (-np.deg2rad(10), np.deg2rad(10))   # ë” ì—„ê²©í•œ roll

        # Domain randomization ì„¤ì •
        self.randomize_physics = True
        self.original_gravity = None

    def reset(self, seed=None, options=None):
        """í™˜ê²½ ë¦¬ì…‹ - 2ì¡± ë³´í–‰ ì‹œì‘ ìì„¸ë¡œ"""
        obs, info = super().reset(seed=seed, options=options)

        # original_gravity ì´ˆê¸°í™”
        if self.original_gravity is None:
            self.original_gravity = self.model.opt.gravity.copy()

        # 2ì¡± ë³´í–‰ ì‹œì‘ ìì„¸ ì„¤ì •
        self._set_standing_initial_pose()

        # Domain randomization
        if self.randomize_physics and self.original_gravity is not None:
            self._apply_domain_randomization()

        self.episode_length = 0
        self._post_reset = True

        # --- ì¶”ê°€ë¨: ì—°ì† ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹ ---
        self.consecutive_failures = 0
        # --- ì¶”ê°€ ë ---

        # ë³´ìƒ í•¨ìˆ˜ ë¦¬ì…‹
        self.standing_reward.num_timesteps = getattr(self, 'total_timesteps', 0)

        return self._get_obs(), info

    def _apply_domain_randomization(self):
        """ë¬¼ë¦¬ íŒŒë¼ë¯¸í„° ëœë¤í™”"""
        if np.random.random() < 0.8:  # 80% í™•ë¥ ë¡œ ëœë¤í™”
            # ì¤‘ë ¥ ëœë¤í™”
            gravity_scale = np.random.uniform(0.9, 1.1)
            self.model.opt.gravity[:] = self.original_gravity * gravity_scale

            # ë§ˆì°° ê³„ìˆ˜ ëœë¤í™”
            friction_scale = np.random.uniform(0.8, 1.2)
            for i in range(self.model.ngeom):
                if hasattr(self.model, 'geom_friction'):
                    self.model.geom_friction[i, :] *= friction_scale

            # ì§ˆëŸ‰ ëœë¤í™” (ì‘ì€ ë²”ìœ„)
            mass_scale = np.random.uniform(0.95, 1.05)
            for i in range(self.model.nbody):
                if self.model.body_mass[i] > 0:
                    self.model.body_mass[i] *= mass_scale

    def _set_standing_initial_pose(self):
        """ê°œì„ ëœ ì´ˆê¸° ìì„¸ ì„¤ì •"""
        # íŠ¸ë í¬ ìœ„ì¹˜
        self.data.qpos[0] = np.random.uniform(-0.1, 0.1)  # ì•½ê°„ì˜ ëœë¤ì„±
        self.data.qpos[1] = np.random.uniform(-0.1, 0.1)
        self.data.qpos[2] = 0.5

        # íŠ¸ë í¬ ìì„¸ (ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€)
        self.data.qpos[3] = 1.0
        self.data.qpos[4:7] = np.random.normal(0, 0.01, 3)

        # ì¿¼í„°ë‹ˆì–¸ ì •ê·œí™”
        quat_norm = np.linalg.norm(self.data.qpos[3:7])
        self.data.qpos[3:7] /= quat_norm

        # ê´€ì ˆ ì´ˆê¸°í™” (ì•½ê°„ì˜ ëœë¤ì„±)
        for i in range(self.model.nu):
            self.data.ctrl[i] = np.random.uniform(-0.01, 0.01)

        self.data.qvel[:] = 0.0
        self.data.qacc[:] = 0.0

        # ë’·ë‹¤ë¦¬ëŠ” êµ¬ë¶€ë¦¬ê³ , ì•ë‹¤ë¦¬ëŠ” ë“¤ì–´ì˜¬ë¦° ìì„¸
        joint_targets = np.zeros(12)
        # ë’·ë‹¤ë¦¬ (RR, RL) - êµ¬ë¶€ë¦° ìì„¸
        joint_targets[6:9] = [0.0, 0.8, -1.6]  # RR
        joint_targets[9:12] = [0.0, 0.8, -1.6]  # RL
        # ì•ë‹¤ë¦¬ (FR, FL) - ë“¤ì–´ì˜¬ë¦° ìì„¸
        joint_targets[0:3] = [0.0, 1.2, -2.0]  # FR
        joint_targets[3:6] = [0.0, 1.2, -2.0]  # FL

        # ë…¸ì´ì¦ˆ ì¶”ê°€
        joint_targets += np.random.normal(0, 0.05, 12)
        self.data.qpos[7:19] = joint_targets

        # ì‹œë®¬ë ˆì´í„°ì— í˜„ì¬ ìƒíƒœ ì ìš©
        mujoco.mj_forward(self.model, self.data)

        # ë°œ ë†’ì´ ê¸°ë°˜ z ë³´ì •
        foot_names = ["FR", "FL", "RR", "RL"]
        foot_ids = [self.model.site(name).id for name in foot_names]
        foot_zs = [self.data.site_xpos[site_id][2] for site_id in foot_ids]
        min_foot_z = min(foot_zs[2:])  # ë’·ë°œë§Œ ê³ ë ¤

        target_clearance = 0.02
        self.data.qpos[2] -= (min_foot_z - target_clearance)

        mujoco.mj_forward(self.model, self.data)

    def step(self, action):
        """í™˜ê²½ ìŠ¤í… ì‹¤í–‰"""
        # ì•¡ì…˜ ì‹¤í–‰
        self.do_simulation(action, self.frame_skip)

        # ê´€ì°°ê°’ ê³„ì‚°
        obs = self._get_obs()

        # ë³´ìƒ ê³„ì‚°
        reward, reward_info = self.standing_reward.compute_reward(self.model, self.data)

        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        terminated = self._is_terminated()
        truncated = self.episode_length >= self.max_episode_length

        self.episode_length += 1

        # post_reset í”Œë˜ê·¸ í•´ì œ
        if self._post_reset and self.episode_length > 1:
            self._post_reset = False

        # ì „ì²´ íƒ€ì„ìŠ¤í… ì¶”ì 
        if hasattr(self, 'total_timesteps'):
            self.total_timesteps += 1
        else:
            self.total_timesteps = 1

        info = {
            'episode_length': self.episode_length,
            'standing_reward': reward,
            'standing_success': self._is_standing_successful(),
            'curriculum_stage': self.standing_reward.curriculum_stage,
            **reward_info
        }

        return obs, reward, terminated, truncated, info

    def _is_terminated(self):
        """ê°œì„ ëœ ì¢…ë£Œ ì¡°ê±´ (ì—°ì† ì‹¤íŒ¨ ê¸°ë°˜, ìˆ˜ì •ë¨)"""
        # ë¦¬ì…‹ ì§í›„ ë˜ëŠ” ê·¸ë ˆì´ìŠ¤ ê¸°ê°„ ì¤‘ì—ëŠ” ì¢…ë£Œ ì¡°ê±´ ë¬´ì‹œí•˜ê³  ì¹´ìš´í„° ì´ˆê¸°í™”
        if self.episode_length < self.grace_steps or self._post_reset:
            self.consecutive_failures = 0
            return False

        is_failure = False

        # ê¸°ë³¸ ê±´ê°• ìƒíƒœ í™•ì¸
        if not self.is_healthy:
            is_failure = True

        # zì¶•ì´ ì§€ë‚˜ì¹˜ê²Œ ê¸°ìš¸ì–´ì§„ ê²½ìš°
        trunk_quat = self.data.qpos[3:7]
        up_vector = self.standing_reward._quat_to_rotmat(trunk_quat)[:, 2]
        min_upright = 0.7 + 0.1 * min(self.standing_reward.curriculum_stage / 5, 1.0)
        if up_vector[2] < min_upright:
            is_failure = True

        # ë†’ì´ê°€ ë„ˆë¬´ ë‚®ì€ ê²½ìš°
        if self.data.qpos[2] < 0.3:
            is_failure = True

        # ë„ˆë¬´ ë¹ ë¥¸ íšŒì „
        angular_vel = np.linalg.norm(self.data.qvel[3:6])
        if angular_vel > 10.0:
            is_failure = True

        # ì‹¤íŒ¨ ìƒíƒœì— ë”°ë¼ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        if is_failure:
            self.consecutive_failures += 1
        else:
            self.consecutive_failures = 0

        # ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ê°€ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ì¢…ë£Œ
        if self.consecutive_failures >= self.failure_threshold:
            return True

        return False

    def _is_standing_successful(self):
        """2ì¡± ë³´í–‰ ì„±ê³µ íŒì • (ê°œì„ )"""
        trunk_height = self.data.qpos[2]
        trunk_quat = self.data.qpos[3:7]
        trunk_rotation_matrix = self.standing_reward._quat_to_rotmat(trunk_quat)
        up_vector = trunk_rotation_matrix[:, 2]

        # ë°œ ì ‘ì´‰ í™•ì¸
        foot_contacts = self.standing_reward._get_foot_contacts(self.model, self.data)

        # ì»¤ë¦¬í˜ëŸ¼ì— ë”°ë¥¸ ì„±ê³µ ê¸°ì¤€
        stage = self.standing_reward.curriculum_stage

        # ê¸°ë³¸ ì¡°ê±´
        height_ok = 0.4 < trunk_height < 0.6
        upright_ok = up_vector[2] > (0.85 + 0.02 * stage)
        rear_feet_contact = foot_contacts[2] > 0.5 and foot_contacts[3] > 0.5
        front_feet_up = foot_contacts[0] < 0.3 and foot_contacts[1] < 0.3

        # ì•ˆì •ì„± ì¡°ê±´
        angular_vel = np.linalg.norm(self.data.qvel[3:6])
        stable = angular_vel < 2.0

        # ì§€ì† ì‹œê°„ ì¡°ê±´ (ìŠ¤í…Œì´ì§€ë³„ë¡œ ë‹¤ë¦„)
        min_duration = 50 + 20 * stage
        duration_ok = self.episode_length > min_duration

        # ì „ì§„ ì¡°ê±´ (ë†’ì€ ìŠ¤í…Œì´ì§€ì—ì„œë§Œ)
        forward_vel = self.data.qvel[0]
        if stage >= 3:
            moving_forward = forward_vel > 0.1
        else:
            moving_forward = True  # ì´ˆê¸°ì—ëŠ” ì „ì§„ ì¡°ê±´ ë¬´ì‹œ

        return (height_ok and upright_ok and rear_feet_contact and
                front_feet_up and duration_ok and stable and moving_forward)


class GradualStandingEnv(Go1StandingEnv):
    """ì ì§„ì ìœ¼ë¡œ 4ì¡±ì—ì„œ 2ì¡± ë³´í–‰ìœ¼ë¡œ ì „í™˜í•˜ëŠ” í™˜ê²½ (ìˆ˜ì •ë¨)"""

    def __init__(self, curriculum_stage=0, **kwargs):
        super().__init__(**kwargs)
        self.curriculum_stage = curriculum_stage
        self._setup_curriculum()

    def _setup_curriculum(self):
        """ì»¤ë¦¬í˜ëŸ¼ ë‹¨ê³„ë³„ ì„¤ì •"""
        if self.curriculum_stage == 0:
            # Stage 0: ì•ˆì •ì ì¸ 4ì¡± ë³´í–‰ì— ì§‘ì¤‘
            self.reward_weights = {
                'quadruped': 0.9,  # 4ì¡± ë³´í–‰ ë³´ìƒ ë¹„ì¤‘ì„ ë†’ì„
                'standing': 0.1
            }
            self.grace_steps = 30  # ìœ ì˜ˆ ì‹œê°„ ì¦ê°€
            self.max_episode_length = 500
            # Stage 0ì—ì„œëŠ” 4ì¡± ë³´í–‰ì— ë§ëŠ” ê±´ê°• ë²”ìœ„ë¥¼ ì‚¬ìš©
            self._healthy_z_range = (0.2, 0.5)
            self._healthy_pitch_range = (-np.deg2rad(30), np.deg2rad(30))
            self._healthy_roll_range = (-np.deg2rad(25), np.deg2rad(25))

        elif self.curriculum_stage == 1:
            # Stage 1: ì•ë°œ ë“¤ê¸° ì—°ìŠµ
            self.reward_weights = {
                'quadruped': 0.6,  # ì ì§„ì ìœ¼ë¡œ ë¹„ì¤‘ ë³€ê²½
                'standing': 0.4
            }
            self.grace_steps = 20
            self.max_episode_length = 750
            # 2ì¡± ë³´í–‰ ìì„¸ë¡œ ì „í™˜
            self._healthy_z_range = (0.3, 0.6)
            self._healthy_pitch_range = (-np.deg2rad(20), np.deg2rad(20))
            self._healthy_roll_range = (-np.deg2rad(15), np.deg2rad(15))

        elif self.curriculum_stage == 2:
            # Stage 2: 2ì¡± ìì„¸ ìœ ì§€
            self.reward_weights = {
                'quadruped': 0.2,
                'standing': 0.8
            }
            self.grace_steps = 10
            self.max_episode_length = 1000
            # 2ì¡± ë³´í–‰ ìì„¸ì— ë” ê°€ê¹Œì›Œì§
            self._healthy_z_range = (0.35, 0.65)
            self._healthy_pitch_range = (-np.deg2rad(15), np.deg2rad(15))
            self._healthy_roll_range = (-np.deg2rad(10), np.deg2rad(10))

        else:
            # Stage 3+: ì™„ì „í•œ 2ì¡± ë³´í–‰
            self.reward_weights = {
                'quadruped': 0.0,
                'standing': 1.0
            }
            self.grace_steps = 5
            self.max_episode_length = 1500
            # ìµœì¢… 2ì¡± ë³´í–‰ ìì„¸
            self._healthy_z_range = (0.35, 0.65)
            self._healthy_pitch_range = (-np.deg2rad(15), np.deg2rad(15))
            self._healthy_roll_range = (-np.deg2rad(10), np.deg2rad(10))

    def step(self, action):
        """í˜¼í•© ë³´ìƒì„ ì‚¬ìš©í•œ ìŠ¤í…"""
        # ê¸°ë³¸ ìŠ¤í… ì‹¤í–‰
        self.do_simulation(action, self.frame_skip)

        obs = self._get_obs()

        # 2ì¡± ë³´í–‰ ë³´ìƒ
        standing_reward, standing_info = self.standing_reward.compute_reward(self.model, self.data)

        # 4ì¡± ë³´í–‰ ë³´ìƒ (í•„ìš”ì‹œ)
        if self.reward_weights['quadruped'] > 0:
            quadruped_reward = self._compute_quadruped_reward()
        else:
            quadruped_reward = 0

        # í˜¼í•© ë³´ìƒ
        total_reward = (self.reward_weights['standing'] * standing_reward +
                        self.reward_weights['quadruped'] * quadruped_reward)

        terminated = self._is_terminated()
        truncated = self.episode_length >= self.max_episode_length

        self.episode_length += 1

        info = {
            'episode_length': self.episode_length,
            'standing_reward': standing_reward,
            'quadruped_reward': quadruped_reward,
            'total_reward': total_reward,
            'curriculum_stage': self.curriculum_stage,
            'standing_success': self._is_standing_successful(),
            **standing_info
        }

        return obs, total_reward, terminated, truncated, info

    def _compute_quadruped_reward(self):
        """ê°„ë‹¨í•œ 4ì¡± ë³´í–‰ ë³´ìƒ"""
        # ì „ì§„ ì†ë„
        forward_vel = self.data.qvel[0]
        vel_reward = np.clip(forward_vel, 0, 1)

        # ì•ˆì •ì„±
        angular_vel = np.linalg.norm(self.data.qvel[3:6])
        stability_reward = np.exp(-angular_vel)

        # ì—ë„ˆì§€ íš¨ìœ¨
        energy = np.sum(np.square(self.data.ctrl))
        energy_reward = np.exp(-0.01 * energy)

        return vel_reward + 0.5 * stability_reward + 0.1 * energy_reward

    def advance_curriculum(self, success_rate):
        """ì„±ê³µë¥ ì— ë”°ë¼ ì»¤ë¦¬í˜ëŸ¼ ì§„í–‰"""
        if success_rate > 0.8 and self.curriculum_stage < 5:
            self.curriculum_stage += 1
            self._setup_curriculum()
            # ë³´ìƒ í•¨ìˆ˜ì˜ ì»¤ë¦¬í˜ëŸ¼ë„ ì—…ë°ì´íŠ¸
            self.standing_reward.curriculum_stage = self.curriculum_stage
            print(f"ğŸ“ ì»¤ë¦¬í˜ëŸ¼ ì§„í–‰: Stage {self.curriculum_stage}")
            return True
        return False