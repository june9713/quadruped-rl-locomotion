#4ì¡±ë³´í–‰ ë¡œë´‡ì„ ì´ìš©í•œ ì‹¤í—˜ì  2ì¡±ë³´í–‰ í›ˆë ¨ ì½”ë“œë“œ
from gymnasium import spaces
from gymnasium.envs.mujoco import MujocoEnv
import mujoco
import numpy as np
from pathlib import Path
import time
import random

DEFAULT_CAMERA_CONFIG = {
    "azimuth": 90.0,
    "distance": 3.0,
    "elevation": -25.0,
    "lookat": np.array([0., 0., 0.]),
    "fixedcamid": 0,
    "trackbodyid": -1,
    "type": 2,
}

class Go1MujocoEnv(MujocoEnv):
    """Optimized bipedal walking environment for Go1 robot."""
    
    metadata = {
        "render_modes": ["human", "rgb_array", "depth_array"],
    }
    
    BIPEDAL_READY_JOINTS = np.array([
        0.0, 3.8, -2.2,    # FR
        0.0, 3.8, -2.2,    # FL
        0.0, 2.6, -1.4,    # RR
        0.0, 2.6, -1.4,    # RL
    ])
    
    def __init__(self, ctrl_type="torque", biped=False, rand_power=0.0, action_noise=0.0, **kwargs):
        model_path = Path(f"./unitree_go1/scene_{ctrl_type}.xml")
        self.biped = biped
        self._rand_power = rand_power
        
        self._action_noise_scale = action_noise
        self._time_since_last_noise = 0.0

        MujocoEnv.__init__(
            self,
            model_path=model_path.absolute().as_posix(),
            frame_skip=10,
            observation_space=None,
            default_camera_config=DEFAULT_CAMERA_CONFIG,
            **kwargs,
        )
        
        self.metadata = {
            "render_modes": ["human", "rgb_array", "depth_array"],
            "render_fps": 60,
        }
        
        self._last_render_time = -1.0
        self._max_episode_time_sec = 20.0
        self._step = 0
        self._front_feet_touched = False
        self._episode_count = 0
        self._success_count = 0
        
        # ==========================================
        # ì •ê·œí™”ëœ ë³´ìƒ ê°€ì¤‘ì¹˜ (ìµœëŒ€: 10.0)
        # ==========================================
        self.reward_weights = {
            # í•µì‹¬ ëª©í‘œ (7-10 ë²”ìœ„)
            "biped_perfect_upright": 10.0,       # ìµœìš°ì„ : ì™„ë²½í•œ ì§ë¦½ ìì„¸
            "balance_stability": 8.0,            # ê· í˜• ì•ˆì •ì„±
            "biped_front_feet_off_ground": 8.0,  # ì•ë°œ ë“¤ê¸° (í•µì‹¬!)
            "forward_velocity": 7.0,             # ì „ì§„ ì†ë„
            
            # ë³´ì¡° ëª©í‘œ (3-5 ë²”ìœ„)
            "biped_upright": 5.0,                # ëª¸í†µ ì§ë¦½ ì •ë ¬
            "feet_airtime": 4.0,                 # ë°œ ì²´ê³µ ì‹œê°„
            
            # ê¸°ë³¸ ë³´ìƒ (0.5-2 ë²”ìœ„)
            "linear_vel_tracking": 1.0,          # ì„ ì†ë„ ì¶”ì 
            "angular_vel_tracking": 0.8,         # ê°ì†ë„ ì¶”ì 
            "healthy": 0.5,                      # ìƒì¡´ ë³´ìƒ
        }
        
        # ==========================================
        # ì •ê·œí™”ëœ ë¹„ìš© ê°€ì¤‘ì¹˜ (ìµœëŒ€: 10.0, ìµœì†Œ: 0.01)
        # ==========================================
        self.cost_weights = {
            # ë ˆë²¨ 1: ì¹˜ëª…ì  ì‹¤íŒ¨ (8-10 ë²”ìœ„)
            "flipped_over": 10.0,                # ë’¤ì§‘í˜ - ìµœëŒ€ í˜ë„í‹°
            "hip_ground_contact": 9.0,           # hipì´ ë•…ì— ë‹¿ìŒ
            "shoulder_below_pelvis": 8.0,        # ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ìŒ
            
            # ë ˆë²¨ 2: ì£¼ìš” ì‹¤íŒ¨ (4-7 ë²”ìœ„)
            "biped_unwanted_contact": 6.0,       # ì›ì¹˜ ì•ŠëŠ” ì ‘ì´‰
            "biped_front_feet_below_hips": 5.0,  # ì•ë°œì´ ì—‰ë©ì´ë³´ë‹¤ ë‚®ìŒ
            "biped_front_contact": 4.0,          # ì•ë°œ ì ‘ì´‰ (ê¸°ì¡´ 80ì—ì„œ ëŒ€í­ ê°ì†Œ)
            "joint_limit": 4.0,                  # ê´€ì ˆ í•œê³„
            
            # ë ˆë²¨ 3: ìì„¸ ì œì•½ (1-3 ë²”ìœ„)
            "self_collision": 3.0,               # ìê°€ ì¶©ëŒ
            "biped_pitch_stability": 2.0,        # í”¼ì¹˜ ì•ˆì •ì„±
            "biped_roll_stability": 2.0,         # ë¡¤ ì•ˆì •ì„±
            "biped_low_rear_hips": 1.5,         # ë‚®ì€ ë’·ë‹¤ë¦¬ ì—‰ë©ì´
            "biped_body_height": 1.5,           # ëª¸ì²´ ë†’ì´
            "collision": 1.0,                    # ì¼ë°˜ ì¶©ëŒ
            
            # ë ˆë²¨ 4: ë¶€ë“œëŸ¬ìš´ ë™ì‘ (0.1-0.9 ë²”ìœ„)
            "biped_front_foot_height": 0.8,      # ì•ë°œ ë†’ì´
            "biped_crossed_legs": 0.6,          # ë‹¤ë¦¬ êµì°¨
            "biped_rear_feet_airborne": 0.5,    # ë’·ë°œ ì²´ê³µ
            "vertical_vel": 0.4,                # ìˆ˜ì§ ì†ë„
            "orientation": 0.3,                  # ë°©í–¥
            
            # ë ˆë²¨ 5: ë¯¸ì„¸ ì¡°ì • (0.01-0.09 ë²”ìœ„)
            "biped_abduction_joints": 0.08,     # ì™¸ì „ ê´€ì ˆ
            "xy_angular_vel": 0.05,             # XY ê°ì†ë„
            "default_joint_position": 0.05,     # ê¸°ë³¸ ê´€ì ˆ ìœ„ì¹˜
            "joint_velocity": 0.03,             # ê´€ì ˆ ì†ë„
            "action_rate": 0.02,                # ì•¡ì…˜ ë³€í™”ìœ¨
            "torque": 0.01,                     # í† í¬ (ìµœì†Œê°’)
            "joint_acceleration": 0.01,         # ê´€ì ˆ ê°€ì†ë„ (ìµœì†Œê°’)
        }
            
        self._curriculum_base = 0.3
        self._gravity_vector = np.array(self.model.opt.gravity)
        self._default_joint_position = np.array(self.model.key_ctrl[0])
        
        self._desired_velocity_min = np.array([0.0, -0.1, -0.1])
        self._desired_velocity_max = np.array([0.3, 0.1, 0.1])
        self._desired_velocity = self._sample_desired_vel()
        
        self._obs_scale = {
            "linear_velocity": 2.0,
            "angular_velocity": 0.25,
            "dofs_position": 1.0,
            "dofs_velocity": 0.05,
        }
        
        self._tracking_velocity_sigma = 0.25
        
        self._healthy_z_range = (0.20, 1.8)
        self._healthy_pitch_range = (-np.pi, 0.0)
        self._healthy_roll_range = (-np.deg2rad(85), np.deg2rad(85))
        
        self._feet_air_time = np.zeros(4)
        self._last_contacts = np.zeros(4)
        self._cfrc_ext_feet_indices = [4, 7, 10, 13]
        self._cfrc_ext_front_feet_indices = [4, 7]
        self._cfrc_ext_contact_indices = [2, 3, 5, 6, 8, 9, 11, 12]
        
        dof_position_limit_multiplier = 0.95
        ctrl_range_offset = (
            0.5 * (1 - dof_position_limit_multiplier) * (self.model.actuator_ctrlrange[:, 1] - self.model.actuator_ctrlrange[:, 0])
        )
        self._soft_joint_range = np.copy(self.model.actuator_ctrlrange)
        self._soft_joint_range[:, 0] += ctrl_range_offset
        self._soft_joint_range[:, 1] -= ctrl_range_offset
        
        self._reset_noise_scale = 0.05
        self._last_action = np.zeros(12)
        self._last_feet_contact_forces = np.zeros(4)
        self._clip_obs_threshold = 100.0
        self._balance_history = []
        self._max_balance_history = 10
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(48,), dtype=np.float64
        )
        
        feet_site = ["FR", "FL", "RR", "RL"]
        self._feet_site_name_to_id = {
            f: mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE.value, f)
            for f in feet_site
        }
        self._main_body_id = mujoco.mj_name2id(
            self.model, mujoco.mjtObj.mjOBJ_BODY.value, "trunk"
        )
        
        self._initialize_biped_body_ids()

        self._time_flipped_over = 0.0
        self._time_shoulder_below_pelvis = 0.0
        self._time_hip_on_ground = 0.0
        
        # ==========================================
        # ë³´ìƒ ì •ê·œí™”ë¥¼ ìœ„í•œ ì¶”ê°€ ë³€ìˆ˜
        # ==========================================
        self._reward_normalizer_window = 1000
        self._reward_history = []
        self._cost_history = []
        
        # ìŠ¤ì¼€ì¼ ê²€ì¦ ì¶œë ¥
        self._validate_weight_scales()

    def _validate_weight_scales(self):
        """ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ ë²”ìœ„ë¥¼ ê²€ì¦í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤."""
        max_reward = max(self.reward_weights.values())
        min_reward = min(self.reward_weights.values())
        max_cost = max(self.cost_weights.values())
        min_cost = min(self.cost_weights.values())
        
        print("=" * 50)
        print("ğŸ“Š ë³´ìƒ/ë¹„ìš© ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ ë¶„ì„")
        print("=" * 50)
        print(f"âœ… ë³´ìƒ ë²”ìœ„: {min_reward:.2f} ~ {max_reward:.2f} (ë¹„ìœ¨ {max_reward/min_reward:.1f}:1)")
        print(f"âœ… ë¹„ìš© ë²”ìœ„: {min_cost:.2f} ~ {max_cost:.2f} (ë¹„ìœ¨ {max_cost/min_cost:.1f}:1)")
        print(f"âœ… ì „ì²´ ë™ì  ë²”ìœ„: {max_reward/min_cost:.0f}:1")
        print("=" * 50)
        
        # ê²½ê³  ì²´í¬
        if max_reward > 10.0:
            print("âš ï¸ ê²½ê³ : ìµœëŒ€ ë³´ìƒì´ 10.0ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!")
        if min_cost < 0.01:
            print("âš ï¸ ê²½ê³ : ìµœì†Œ ë¹„ìš©ì´ 0.01 ë¯¸ë§Œì…ë‹ˆë‹¤!")
        if max_reward/min_cost > 1000:
            print("âš ï¸ ê²½ê³ : ë™ì  ë²”ìœ„ê°€ 1000:1ì„ ì´ˆê³¼í•©ë‹ˆë‹¤!")

    def _apply_curriculum_scaling(self, weight_dict):
        """ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ì§„í–‰ë„ì— ë”°ë¼ ê°€ì¤‘ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤."""
        scaled_weights = weight_dict.copy()
        curriculum = self.curriculum_factor
        
        if curriculum < 0.3:  # ì´ˆê¸° ë‹¨ê³„: ì•ˆì •ì„± ì¤‘ì‹¬
            stability_keys = ["balance_stability", "biped_perfect_upright", "flipped_over", "hip_ground_contact"]
            for key in stability_keys:
                if key in scaled_weights:
                    scaled_weights[key] *= 1.3
                    
        elif curriculum < 0.7:  # ì¤‘ê°„ ë‹¨ê³„: ë™ì‘ í•™ìŠµ
            motion_keys = ["biped_front_feet_off_ground", "forward_velocity", "biped_front_contact"]
            for key in motion_keys:
                if key in scaled_weights:
                    if "contact" in key:  # ì ‘ì´‰ í˜ë„í‹°ëŠ” ê°ì†Œ
                        scaled_weights[key] *= 0.7
                    else:  # ë™ì‘ ë³´ìƒì€ ì¦ê°€
                        scaled_weights[key] *= 1.2
                        
        else:  # í›„ê¸° ë‹¨ê³„: ì„±ëŠ¥ ìµœì í™”
            performance_keys = ["forward_velocity", "feet_airtime", "torque", "action_rate"]
            for key in performance_keys:
                if key in scaled_weights:
                    if key in ["torque", "action_rate"]:  # íš¨ìœ¨ì„± í˜ë„í‹° ê°ì†Œ
                        scaled_weights[key] *= 0.5
                    else:  # ì„±ëŠ¥ ë³´ìƒ ì¦ê°€
                        scaled_weights[key] *= 1.3
        
        return scaled_weights

    def _normalize_reward_value(self, value, max_val=10.0):
        """ë³´ìƒ ê°’ì„ ì •ê·œí™”í•©ë‹ˆë‹¤ (tanh ê¸°ë°˜ ë¶€ë“œëŸ¬ìš´ í¬í™”)."""
        if abs(value) < 0.001:
            return 0.0
        return np.tanh(value / max_val) * max_val
    
    def _initialize_biped_body_ids(self):
        front_knee_body_names = ["FR_calf", "FL_calf"]
        self._front_knee_body_ids = [
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in front_knee_body_names
        ]
        
        self._front_feet_site_ids = [
            self._feet_site_name_to_id["FR"],
            self._feet_site_name_to_id["FL"]
        ]
        
        rear_hip_body_names = ["RR_hip", "RL_hip"]
        self._rear_hip_body_ids = [
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in rear_hip_body_names
        ]
        self._rear_hips_min_height = 0.18
        
        front_hip_body_names = ["FR_hip", "FL_hip"]
        self._front_hip_body_ids = [
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in front_hip_body_names
        ]
        
        unwanted_contact_body_names = [
            "trunk", "FR_thigh", "FL_thigh", "RR_thigh", "RL_thigh", "FR_calf", "FL_calf",
        ]
        self._unwanted_contact_body_ids = [
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in unwanted_contact_body_names
        ]
        
        self._front_right_limb_body_ids = {
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in ["FR_hip", "FR_thigh", "FR_calf"]
        }
        self._front_left_limb_body_ids = {
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in ["FL_hip", "FL_thigh", "FL_calf"]
        }
        self._rear_right_limb_body_ids = {
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in ["RR_hip", "RR_thigh", "RR_calf"]
        }
        self._rear_left_limb_body_ids = {
            mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY.value, name)
            for name in ["RL_hip", "RL_thigh", "RL_calf"]
        }
    
    @property
    def curriculum_factor(self):
        progress = min(1.0, self._episode_count / 1000.0)
        return progress
    @property
    def _trunk_up_alignment(self):
        """Helper to get alignment of trunk's z-axis with world's up-axis."""
        world_up_vector = np.array([0, 0, 1])
        # ëª¸í†µ íšŒì „ í–‰ë ¬ì˜ 3ë²ˆì§¸ ì—´ì´ ëª¸í†µì˜ Zì¶•(Up ë²¡í„°)ì„ ì›”ë“œ ì¢Œí‘œê³„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        trunk_up_vector = self.data.xmat[self._main_body_id].reshape(3, 3)[:, 2]
        return np.dot(trunk_up_vector, world_up_vector)

    @property
    def is_flipped_over(self):
        """Check if the robot is flipped over."""
        # ëª¸í†µì˜ Up ë²¡í„°ì™€ ì„¸ìƒì˜ Up ë²¡í„°ì˜ ë‚´ì  ê°’ì´ ìŒìˆ˜ì´ë©´ ë’¤ì§‘íŒ ìƒíƒœì…ë‹ˆë‹¤.
        return self._trunk_up_alignment < 0.0

    @property
    def flipped_over_cost(self):
        """Calculate cost for being flipped over."""
        alignment = self._trunk_up_alignment
        if alignment < 0:
            # ë’¤ì§‘í˜”ì„ ë•Œ, alignment ê°’ì€ 0 ~ -1 ì‚¬ì´ì…ë‹ˆë‹¤.
            # ì œê³±ì„ í•˜ì—¬ -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ (ì™„ì „íˆ ë’¤ì§‘íìˆ˜ë¡) ë¹„ìš©ì´ 1ì— ê°€ê¹ê²Œ ì¦ê°€í•©ë‹ˆë‹¤.
            return np.square(alignment)
        return 0.0


    @property
    def forward_velocity_reward(self):
        forward_vel = self.data.qvel[0]
        target_vel = 0.2
        vel_error = abs(forward_vel - target_vel)
        reward = np.exp(-5.0 * vel_error)
        if forward_vel < 0:
            reward *= 0.1
        return reward
    
    @property
    def balance_stability_reward(self):
        w, x, y, z = self.data.qpos[3:7]
        roll, pitch, _ = self.euler_from_quaternion(w, x, y, z)
        target_pitch = np.deg2rad(-90)
        pitch_error = abs(pitch - target_pitch)
        roll_error = abs(roll)
        balance_score = np.exp(-3.0 * (pitch_error + roll_error))
        self._balance_history.append(balance_score)
        if len(self._balance_history) > self._max_balance_history:
            self._balance_history.pop(0)
        return np.mean(self._balance_history) if self._balance_history else balance_score
    
    @property
    def adaptive_joint_acceleration_cost(self):
        joint_velocities = np.abs(self.data.qvel[6:])
        joint_accelerations = self.data.qacc[6:]
        epsilon = 1e-6
        penalty_scale = 1.0 + self.curriculum_factor * 2.0
        dynamic_penalty = np.sum(
            np.square(joint_accelerations) / (joint_velocities + epsilon)
        ) * penalty_scale
        return dynamic_penalty
    
    @property
    def biped_perfect_upright_reward(self):
        w, x, y, z = self.data.qpos[3:7]
        _, pitch, _ = self.euler_from_quaternion(w, x, y, z)
        target_pitch = np.deg2rad(-90)
        pitch_error = abs(pitch - target_pitch)
        max_error = np.deg2rad(60)
        if pitch_error > max_error:
            return 0.0
        reward = np.exp(-8 * pitch_error / max_error)
        if pitch_error < np.deg2rad(10):
            reward *= 1.5
        return reward
    
    @property
    def biped_front_feet_off_ground_reward(self):
        front_contact_forces = self.front_feet_contact_forces
        both_feet_off_ground = np.all(front_contact_forces <= 1.0)
        return float(both_feet_off_ground)
    
    @property
    def acceleration_cost(self):
        joint_velocities = np.abs(self.data.qvel[6:])
        joint_accelerations = self.data.qacc[6:]
        epsilon = 1e-6
        dynamic_penalty = np.sum(
            np.square(joint_accelerations) / (joint_velocities + epsilon)
        )
        return dynamic_penalty
    
    @property
    def self_collision_cost(self):
        cost = 0
        for i in range(self.data.ncon):
            contact = self.data.contact[i]
            body1_id = self.model.geom_bodyid[contact.geom1]
            body2_id = self.model.geom_bodyid[contact.geom2]
            
            if (body1_id in self._front_right_limb_body_ids and 
                body2_id in self._front_left_limb_body_ids):
                cost += 0.5
            elif (body2_id in self._front_right_limb_body_ids and 
                  body1_id in self._front_left_limb_body_ids):
                cost += 0.5
            elif (body1_id in self._rear_right_limb_body_ids and 
                  body2_id in self._rear_left_limb_body_ids):
                cost += 0.5
            elif (body2_id in self._rear_right_limb_body_ids and 
                  body1_id in self._rear_left_limb_body_ids):
                cost += 0.5
        return cost
    
    @property
    def biped_crossed_legs_cost(self):
        rear_hips_pos = self.data.xpos[self._rear_hip_body_ids]
        y_rr = rear_hips_pos[0, 1]
        y_rl = rear_hips_pos[1, 1]
        cost = max(0, y_rr - y_rl)
        return cost
    
    @property
    def biped_low_rear_hips_cost(self):
        rear_hips_pos = self.data.xpos[self._rear_hip_body_ids]
        hips_z = rear_hips_pos[:, 2]
        height_difference = self._rear_hips_min_height - hips_z
        cost = np.sum(height_difference.clip(min=0.0))
        return cost * 8.0
    
    @property
    def biped_front_feet_below_hips_cost(self):
        front_feet_pos = self.data.site_xpos[self._front_feet_site_ids]
        front_hips_pos = self.data.xpos[self._front_hip_body_ids]
        feet_z = front_feet_pos[:, 2]
        hips_z = front_hips_pos[:, 2]
        height_difference = hips_z - feet_z
        cost = np.sum(np.square(height_difference.clip(min=0.0)))
        return cost
    
    @property
    def trunk_forward_axis_in_world(self):
        return self.data.xmat[self._main_body_id].reshape(3, 3)[:, 0]
    
    @property
    def front_feet_contact_forces(self):
        front_feet_forces = self.data.cfrc_ext[self._cfrc_ext_front_feet_indices]
        return np.linalg.norm(front_feet_forces, axis=1)
    
    @property
    def biped_upright_reward(self):
        world_up_vector = np.array([0, 0, 1])
        trunk_forward_vector = self.trunk_forward_axis_in_world
        alignment = np.dot(trunk_forward_vector, world_up_vector)
        return max(0, alignment)
    
    @property
    def biped_front_foot_height_cost(self):
        front_feet_pos = self.data.site_xpos[self._front_feet_site_ids]
        front_knees_pos = self.data.xpos[self._front_knee_body_ids]
        feet_z = front_feet_pos[:, 2]
        knees_z = front_knees_pos[:, 2]
        height_difference = knees_z - feet_z
        cost = np.sum(height_difference.clip(min=0.0))
        return cost
    
    @property
    def biped_body_height_cost(self):
        z_pos = self.data.qpos[2]
        if z_pos < 0.25:
            penalty = np.exp((0.25 - z_pos) * 10) - 1
            return penalty
        return 0.0
    
    @property
    def biped_roll_stability_cost(self):
        w, x, y, z = self.data.qpos[3:7]
        roll, _, _ = self.euler_from_quaternion(w, x, y, z)
        soft_limit = np.deg2rad(35)
        hard_limit = np.deg2rad(50)
        roll_abs = abs(roll)
        if roll_abs > hard_limit:
            return np.square((roll_abs - soft_limit) * 4)
        elif roll_abs > soft_limit:
            return (roll_abs - soft_limit) * 1.5
        return 0.0
    
    @property
    def biped_pitch_stability_cost(self):
        w, x, y, z = self.data.qpos[3:7]
        _, pitch, _ = self.euler_from_quaternion(w, x, y, z)
        target_pitch = np.deg2rad(-90)
        pitch_error = abs(pitch - target_pitch)
        soft_limit = np.deg2rad(35)
        hard_limit = np.deg2rad(65)
        if pitch_error > hard_limit:
            return np.square((pitch_error - soft_limit) * 2.5)
        elif pitch_error > soft_limit:
            return (pitch_error - soft_limit) * 1.2
        return 0.0
    
    @property
    def shoulder_below_pelvis_cost(self):
        """ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ì„ ë•Œì˜ ë¹„ìš©ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.biped:
            return 0.0
        
        # ì–´ê¹¨ ìœ„ì¹˜ (FR_hip, FL_hipì˜ í‰ê· )
        shoulder_pos = self.data.xpos[self._front_hip_body_ids]
        shoulder_z = np.mean(shoulder_pos[:, 2])
        
        # ê³¨ë°˜ ìœ„ì¹˜ (RR_hip, RL_hipì˜ í‰ê· )
        pelvis_pos = self.data.xpos[self._rear_hip_body_ids]
        pelvis_z = np.mean(pelvis_pos[:, 2])
        
        # ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ì„ ë•Œì˜ ë†’ì´ ì°¨ì´
        height_difference = pelvis_z - shoulder_z
        
        if height_difference > 0:  # ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ìŒ
            # ë†’ì´ ì°¨ì´ê°€ í´ìˆ˜ë¡ ë¹„ìš©ì´ ê¸‰ê²©íˆ ì¦ê°€
            return np.square(height_difference) * 10.0
        return 0.0
    
    @property
    def is_shoulder_below_pelvis(self):
        """ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ì€ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if not self.biped:
            return False
        
        shoulder_pos = self.data.xpos[self._front_hip_body_ids]
        shoulder_z = np.mean(shoulder_pos[:, 2])
        
        pelvis_pos = self.data.xpos[self._rear_hip_body_ids]
        pelvis_z = np.mean(pelvis_pos[:, 2])
        
        return shoulder_z < pelvis_z
    
    @property
    def is_hip_on_ground(self):
        """hipì´ ë•…ì— ë‹¿ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        # ëª¨ë“  hip bodyë“¤ì˜ ì ‘ì´‰ í˜ì„ í™•ì¸
        all_hip_body_ids = self._front_hip_body_ids + self._rear_hip_body_ids
        hip_contact_forces = self.data.cfrc_ext[all_hip_body_ids]
        
        # ì ‘ì´‰ í˜ì˜ í¬ê¸°ê°€ ì„ê³„ê°’(0.1)ì„ ì´ˆê³¼í•˜ë©´ ë•…ì— ë‹¿ì€ ê²ƒìœ¼ë¡œ íŒë‹¨
        contact_threshold = 0.1
        return np.any(np.linalg.norm(hip_contact_forces, axis=1) > contact_threshold)
    
    @property
    def hip_ground_contact_cost(self):
        """hipì´ ë•…ì— ë‹¿ì„ ë•Œì˜ ë¹„ìš©ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.is_hip_on_ground:
            return 0.0
        
        # hipì´ ë•…ì— ë‹¿ì€ ê²½ìš°, ì ‘ì´‰ í˜ì˜ í¬ê¸°ì— ë¹„ë¡€í•˜ì—¬ ë¹„ìš© ê³„ì‚°
        all_hip_body_ids = self._front_hip_body_ids + self._rear_hip_body_ids
        hip_contact_forces = self.data.cfrc_ext[all_hip_body_ids]
        
        # ì ‘ì´‰ í˜ì˜ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ê³  ì œê³±í•˜ì—¬ ë¹„ìš© ì¦ê°€
        contact_magnitudes = np.linalg.norm(hip_contact_forces, axis=1)
        active_contacts = contact_magnitudes > 0.1
        
        if not np.any(active_contacts):
            return 0.0
        
        # í™œì„± ì ‘ì´‰ì— ëŒ€í•´ì„œë§Œ ë¹„ìš© ê³„ì‚°
        active_contact_forces = contact_magnitudes[active_contacts]
        cost = np.sum(np.square(active_contact_forces))
        
        return cost
    
    @property
    def biped_front_contact_cost(self):
        contact_forces = self.front_feet_contact_forces
        return np.sum(np.power(contact_forces, 1.5))
    
    @property
    def biped_abduction_joints_cost(self):
        abduction_joints_indices = [0, 3, 6, 9]
        dofs_position = self.data.qpos[7:]
        abduction_angles = dofs_position[abduction_joints_indices]
        return np.sum(np.square(abduction_angles))
    
    @property
    def biped_unwanted_contact_cost(self):
        contact_forces = self.data.cfrc_ext[self._unwanted_contact_body_ids]
        cost = np.sum(np.square(np.linalg.norm(contact_forces, axis=1)))
        return cost
    
    def _check_health(self):
        state = self.state_vector()
        
        if not np.isfinite(state).all():
            return False, "state_not_finite", f"State values are not finite: {state}"
        
        # ë’¤ì§‘íŒ ìƒíƒœê°€ 1ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ 
        if self._time_flipped_over > 1.0:
            return False, "flipped_over_timeout", f"Flipped over for {self._time_flipped_over:.2f}s > 1.0s"
        
        # 6. ì–´ê¹¨ê°€ ê³¨ë°˜ë³´ë‹¤ ë‚®ì€ ìƒíƒœê°€ 1ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ
        if self._time_shoulder_below_pelvis > 1.0:
            return False, "shoulder_below_pelvis_timeout", f"Shoulder below pelvis for {self._time_shoulder_below_pelvis:.2f}s > 1.0s"
        
        # 7. hipì´ ë•…ì— ë‹¿ì€ ìƒíƒœê°€ 1ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ì—í”¼ì†Œë“œ ì¢…ë£Œ
        if self._time_hip_on_ground > 1.0:
            return False, "hip_ground_contact_timeout", f"Hip on ground for {self._time_hip_on_ground:.2f}s > 1.0s"
        
        return True, "not_terminated", "Healthy"
    
    def step(self, action):
        self._step += 1
        
        #if self.curriculum_factor < 0.3:
         #   action = 0.7 * self._last_action + 0.3 * action
        
        # âœ¨ --- ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ --- âœ¨
        # 0.5ì´ˆë§ˆë‹¤ ì»¤ë¦¬í˜ëŸ¼ì— ë”°ë¼ ê°•ë„ê°€ ì¡°ì ˆëœ ë…¸ì´ì¦ˆë¥¼ actionì— ì¶”ê°€í•©ë‹ˆë‹¤.
        self._time_since_last_noise += self.dt
        if self._time_since_last_noise > 0.5:#True:#self._action_noise_scale > 0.0 and self._time_since_last_noise > 0.5:
            # ì»¤ë¦¬í˜ëŸ¼ì— ë”°ë¼ í˜„ì¬ ë…¸ì´ì¦ˆ ë ˆë²¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
            #print("noise added")
            current_noise_level = self._action_noise_scale * self.curriculum_factor
            # ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•˜ê³  actionì— ë”í•©ë‹ˆë‹¤.
            noise = np.random.normal(0, current_noise_level, size=action.shape)
            action = action + noise 
            # action ê°’ì´ ìœ íš¨ ë²”ìœ„ [-1, 1]ì„ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¦¬í•‘í•©ë‹ˆë‹¤.
            #action = np.clip(action, -1.0, 1.0)
            # íƒ€ì´ë¨¸ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤.
            self._time_since_last_noise = 0.0
        # âœ¨ --- ìˆ˜ì •ëœ ë¶€ë¶„ ë --- âœ¨

        front_contact_in_step = False
        if np.any(self.front_feet_contact_forces > 1.0):
            front_contact_in_step = True
            self._front_feet_touched = True
        
        self.do_simulation(action, self.frame_skip)
        
        #  ë§¤ ìŠ¤í…ë§ˆë‹¤ ë’¤ì§‘í˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸ 
        if self.is_flipped_over:
            self._time_flipped_over += self.dt
        else:
            self._time_flipped_over = 0.0
        
        # 5. ë§¤ ìŠ¤í…ë§ˆë‹¤ ì–´ê¹¨-ê³¨ë°˜ ë†’ì´ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        if self.is_shoulder_below_pelvis:
            self._time_shoulder_below_pelvis += self.dt
        else:
            self._time_shoulder_below_pelvis = 0.0
        
        # 6. ë§¤ ìŠ¤í…ë§ˆë‹¤ hip ì ‘ì´‰ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
        if self.is_hip_on_ground:
            self._time_hip_on_ground += self.dt
        else:
            self._time_hip_on_ground = 0.0
            
        observation = self._get_obs()
        reward, reward_info = self._calc_reward(action)
        
        # âœ¨ [ì‹ ê·œ ì¶”ê°€] ì‹¤ì‹œê°„ ì €ì¥ì„ ìœ„í•œ ë³´ìƒ ì •ë³´ ì—…ë°ì´íŠ¸
        self._current_episode_reward = getattr(self, '_current_episode_reward', 0.0) + reward
        self._current_episode_length = getattr(self, '_current_episode_length', 0) + 1
        
        terminated = not self.is_healthy
        truncated = self._step >= (self._max_episode_time_sec / self.dt)
        
        info = {
            "x_position": self.data.qpos[0],
            "y_position": self.data.qpos[1],
            "distance_from_origin": np.linalg.norm(self.data.qpos[0:2], ord=2),
            "termination_reason": "not_terminated",
            "termination_details": "No termination",
            "bipedal_success": False,
            **reward_info,
        }
        
        if terminated:
            is_ok, reason, details = self._check_health()
            if not is_ok:
                info["termination_reason"] = reason
                info["termination_details"] = details
        
        if truncated and self.biped and not self._front_feet_touched:
            info["bipedal_success"] = True
            self._success_count += 1
        
        if self.render_mode == "human" and (self.data.time - self._last_render_time) > (
            1.0 / self.metadata["render_fps"]
        ):
            self.render()
            self._last_render_time = self.data.time
        
        self._last_action = action
        self._last_feet_contact_forces = self.feet_contact_forces.copy()
        
        return observation, reward, terminated, truncated, info
    
    @property
    def is_healthy(self):
        is_ok, _, _ = self._check_health()
        return is_ok
    
    @property
    def projected_gravity(self):
        w, x, y, z = self.data.qpos[3:7]
        euler_orientation = np.array(self.euler_from_quaternion(w, x, y, z))
        projected_gravity_not_normalized = (
            np.dot(self._gravity_vector, euler_orientation) * euler_orientation
        )
        if np.linalg.norm(projected_gravity_not_normalized) == 0:
            return projected_gravity_not_normalized
        else:
            return projected_gravity_not_normalized / np.linalg.norm(
                projected_gravity_not_normalized
            )
    
    @property
    def feet_contact_forces(self):
        feet_contact_forces = self.data.cfrc_ext[self._cfrc_ext_feet_indices]
        return np.linalg.norm(feet_contact_forces, axis=1)
    
    @property
    def linear_velocity_tracking_reward(self):
        vel_sqr_error = np.sum(
            np.square(self._desired_velocity[:2] - self.data.qvel[:2])
        )
        return np.exp(-vel_sqr_error / self._tracking_velocity_sigma)
    
    @property
    def angular_velocity_tracking_reward(self):
        vel_sqr_error = np.square(self._desired_velocity[2] - self.data.qvel[5])
        return np.exp(-vel_sqr_error / self._tracking_velocity_sigma)
    
    @property
    def feet_air_time_reward(self):
        feet_contact_force_mag = self.feet_contact_forces
        curr_contact = feet_contact_force_mag > 1.0
        

        rear_feet_contact = curr_contact[2:]
        is_alternating = (rear_feet_contact[0] != rear_feet_contact[1])
        return float(is_alternating)
        
        contact_filter = np.logical_or(curr_contact, self._last_contacts)
        self._last_contacts = curr_contact
        
        first_contact = (self._feet_air_time > 0.0) * contact_filter
        self._feet_air_time += self.dt
        
        time_since_threshold = (self._feet_air_time - 0.2).clip(min=0.0)
        air_time_reward = np.sum(np.square(time_since_threshold) * first_contact)
        
        air_time_reward *= np.linalg.norm(self._desired_velocity[:2]) > 0.1
        
        self._feet_air_time *= ~contact_filter
        
        return air_time_reward
    
    @property
    def healthy_reward(self):
        return self.is_healthy
    
    @property
    def non_flat_base_cost(self):
        return np.sum(np.square(self.projected_gravity[:2]))
    
    @property
    def collision_cost(self):
        return np.sum(
            1.0 * (np.linalg.norm(self.data.cfrc_ext[self._cfrc_ext_contact_indices]) > 0.1)
        )
    
    @property
    def joint_limit_cost(self):
        out_of_range = (self._soft_joint_range[:, 0] - self.data.qpos[7:]).clip(
            min=0.0
        ) + (self.data.qpos[7:] - self._soft_joint_range[:, 1]).clip(min=0.0)
        return np.sum(out_of_range)
    
    @property
    def torque_cost(self):
        return np.sum(np.square(self.data.qfrc_actuator[-12:]))
    
    @property
    def vertical_velocity_cost(self):
        return np.square(self.data.qvel[2])
    
    @property
    def xy_angular_velocity_cost(self):
        return np.sum(np.square(self.data.qvel[3:5]))
    
    def action_rate_cost(self, action):
        return np.sum(np.square(self._last_action - action))
    
    @property
    def joint_velocity_cost(self):
        return np.sum(np.square(self.data.qvel[6:]))
    
    @property
    def default_joint_position_cost(self):
        return np.sum(np.square(self.data.qpos[7:] - self._default_joint_position))
    
    def _calc_reward(self, action):
        """ê°œì„ ëœ ë³´ìƒ ê³„ì‚° í•¨ìˆ˜ (ì •ê·œí™”ëœ ìŠ¤ì¼€ì¼ ì ìš©)"""
        rewards = 0
        costs = 0
        reward_info = {}
        
        # ì»¤ë¦¬í˜ëŸ¼ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        adjusted_reward_weights = self._apply_curriculum_scaling(self.reward_weights)
        adjusted_cost_weights = self._apply_curriculum_scaling(self.cost_weights)
        
        # ==========================================
        # ë³´ìƒ ê³„ì‚° (ì •ê·œí™” ì ìš©)
        # ==========================================
        
        # í•µì‹¬ ë³´ìƒë“¤
        upright_raw = self.biped_perfect_upright_reward
        upright_reward = self._normalize_reward_value(
            upright_raw * adjusted_reward_weights["biped_perfect_upright"], 10.0
        )
        
        forward_vel_raw = self.forward_velocity_reward
        forward_vel_reward = self._normalize_reward_value(
            forward_vel_raw * adjusted_reward_weights["forward_velocity"], 10.0
        )
        
        balance_raw = self.balance_stability_reward
        balance_reward = self._normalize_reward_value(
            balance_raw * adjusted_reward_weights["balance_stability"], 10.0
        )
        
        front_feet_off_raw = self.biped_front_feet_off_ground_reward
        front_feet_off_reward = self._normalize_reward_value(
            front_feet_off_raw * adjusted_reward_weights["biped_front_feet_off_ground"], 10.0
        )
        
        biped_upright_raw = self.biped_upright_reward
        biped_upright_reward = self._normalize_reward_value(
            biped_upright_raw * adjusted_reward_weights["biped_upright"], 10.0
        )
        
        # ë³´ì¡° ë³´ìƒë“¤
        linear_vel_tracking_reward = self._normalize_reward_value(
            self.linear_velocity_tracking_reward * adjusted_reward_weights["linear_vel_tracking"], 10.0
        )
        angular_vel_tracking_reward = self._normalize_reward_value(
            self.angular_velocity_tracking_reward * adjusted_reward_weights["angular_vel_tracking"], 10.0
        )
        healthy_reward = self._normalize_reward_value(
            self.healthy_reward * adjusted_reward_weights["healthy"], 10.0
        )
        feet_air_reward = self._normalize_reward_value(
            self.feet_air_time_reward * adjusted_reward_weights["feet_airtime"], 10.0
        )
        
        # ì´ ë³´ìƒ í•©ì‚°
        rewards = (upright_reward + forward_vel_reward + balance_reward + 
                front_feet_off_reward + biped_upright_reward + linear_vel_tracking_reward + 
                angular_vel_tracking_reward + healthy_reward + feet_air_reward)
        
        # ë³´ìƒ ì •ë³´ ì €ì¥
        reward_info["biped_upright_reward"] = upright_reward
        reward_info["forward_velocity_reward"] = forward_vel_reward
        reward_info["balance_stability_reward"] = balance_reward
        reward_info["front_feet_off_ground_reward"] = front_feet_off_reward
        reward_info["linear_vel_tracking_reward"] = linear_vel_tracking_reward
        reward_info["reward_survive"] = healthy_reward
        
        # ==========================================
        # ë¹„ìš© ê³„ì‚° (ì •ê·œí™” ì ìš©)
        # ==========================================
        
        # ì ì‘ ê³„ìˆ˜ (ì»¤ë¦¬í˜ëŸ¼ì— ë”°ë¼ ê°ì†Œ)
        adaptation_factor = 1.0 - 0.3 * self.curriculum_factor
        
        # ë ˆë²¨ 1: ì¹˜ëª…ì  ì‹¤íŒ¨
        flipped_cost = self._normalize_reward_value(
            self.flipped_over_cost * adjusted_cost_weights["flipped_over"], 10.0
        )
        hip_ground_cost = self._normalize_reward_value(
            self.hip_ground_contact_cost * adjusted_cost_weights["hip_ground_contact"], 10.0
        )
        shoulder_below_cost = self._normalize_reward_value(
            self.shoulder_below_pelvis_cost * adjusted_cost_weights["shoulder_below_pelvis"], 10.0
        )
        
        # ë ˆë²¨ 2: ì£¼ìš” ì‹¤íŒ¨
        unwanted_contact_cost = self._normalize_reward_value(
            self.biped_unwanted_contact_cost * adjusted_cost_weights["biped_unwanted_contact"], 10.0
        )
        front_contact_cost = self._normalize_reward_value(
            self.biped_front_contact_cost * adjusted_cost_weights["biped_front_contact"], 10.0
        )
        front_feet_below_cost = self._normalize_reward_value(
            self.biped_front_feet_below_hips_cost * adjusted_cost_weights["biped_front_feet_below_hips"], 10.0
        )
        joint_limit_cost = self._normalize_reward_value(
            self.joint_limit_cost * adjusted_cost_weights["joint_limit"], 10.0
        )
        
        # ë ˆë²¨ 3: ìì„¸ ì œì•½
        self_collision_cost = self._normalize_reward_value(
            self.self_collision_cost * adjusted_cost_weights["self_collision"], 10.0
        )
        pitch_stability_cost = self._normalize_reward_value(
            self.biped_pitch_stability_cost * adjusted_cost_weights["biped_pitch_stability"], 10.0
        )
        roll_stability_cost = self._normalize_reward_value(
            self.biped_roll_stability_cost * adjusted_cost_weights["biped_roll_stability"], 10.0
        )
        low_rear_hips_cost = self._normalize_reward_value(
            self.biped_low_rear_hips_cost * adjusted_cost_weights["biped_low_rear_hips"], 10.0
        )
        body_height_cost = self._normalize_reward_value(
            self.biped_body_height_cost * adjusted_cost_weights["biped_body_height"], 10.0
        )
        collision_cost = self._normalize_reward_value(
            self.collision_cost * adjusted_cost_weights["collision"], 10.0
        )
        
        # ë ˆë²¨ 4: ë¶€ë“œëŸ¬ìš´ ë™ì‘
        front_foot_height_cost = self._normalize_reward_value(
            self.biped_front_foot_height_cost * adjusted_cost_weights["biped_front_foot_height"], 10.0
        )
        crossed_legs_cost = self._normalize_reward_value(
            self.biped_crossed_legs_cost * adjusted_cost_weights["biped_crossed_legs"], 10.0
        )
        rear_feet_airborne_cost = 0.0
        if np.all(self.feet_contact_forces[2:] < 1.0):
            rear_feet_airborne_cost = self._normalize_reward_value(
                adjusted_cost_weights["biped_rear_feet_airborne"], 10.0
            )
        vertical_vel_cost = self._normalize_reward_value(
            self.vertical_velocity_cost * adjusted_cost_weights["vertical_vel"], 10.0
        )
        orientation_cost = self._normalize_reward_value(
            self.non_flat_base_cost * adjusted_cost_weights["orientation"], 10.0
        )
        
        # ë ˆë²¨ 5: ë¯¸ì„¸ ì¡°ì •
        abduction_joints_cost = self._normalize_reward_value(
            self.biped_abduction_joints_cost * adjusted_cost_weights["biped_abduction_joints"], 10.0
        )
        xy_angular_vel_cost = self._normalize_reward_value(
            self.xy_angular_velocity_cost * adjusted_cost_weights["xy_angular_vel"], 10.0
        )
        default_joint_cost = self._normalize_reward_value(
            self.default_joint_position_cost * adjusted_cost_weights["default_joint_position"], 10.0
        )
        joint_velocity_cost = self._normalize_reward_value(
            self.joint_velocity_cost * adjusted_cost_weights["joint_velocity"] * adaptation_factor, 10.0
        )
        action_rate_cost = self._normalize_reward_value(
            self.action_rate_cost(action) * adjusted_cost_weights["action_rate"] * adaptation_factor, 10.0
        )
        torque_cost = self._normalize_reward_value(
            self.torque_cost * adjusted_cost_weights["torque"] * adaptation_factor, 10.0
        )
        joint_acceleration_cost = self._normalize_reward_value(
            self.acceleration_cost * adjusted_cost_weights["joint_acceleration"], 10.0
        )
        
        # ì´ ë¹„ìš© í•©ì‚°
        costs = (flipped_cost + hip_ground_cost + shoulder_below_cost + 
                unwanted_contact_cost + front_contact_cost + front_feet_below_cost + joint_limit_cost +
                self_collision_cost + pitch_stability_cost + roll_stability_cost + 
                low_rear_hips_cost + body_height_cost + collision_cost +
                front_foot_height_cost + crossed_legs_cost + rear_feet_airborne_cost +
                vertical_vel_cost + orientation_cost +
                abduction_joints_cost + xy_angular_vel_cost + default_joint_cost +
                joint_velocity_cost + action_rate_cost + torque_cost + joint_acceleration_cost)
        
        # ë¹„ìš© ì •ë³´ ì €ì¥ (ìŒìˆ˜ë¡œ ì €ì¥)
        reward_info["flipped_over_cost"] = -flipped_cost
        reward_info["hip_ground_contact_cost"] = -hip_ground_cost
        reward_info["shoulder_below_pelvis_cost"] = -shoulder_below_cost
        reward_info["biped_front_contact_cost"] = -front_contact_cost
        reward_info["biped_unwanted_contact_cost"] = -unwanted_contact_cost
        reward_info["self_collision_cost"] = -self_collision_cost
        reward_info["reward_ctrl"] = -torque_cost
        
        # ==========================================
        # ìµœì¢… ë³´ìƒ ê³„ì‚° (ë²”ìœ„: -10 ~ +10)
        # ==========================================
        raw_reward = rewards - costs
        
        # ì´ë™ í‰ê·  ê¸°ë°˜ ì •ê·œí™” (ì„ íƒì )
        if len(self._reward_history) > 10:
            self._reward_history.append(rewards)
            self._cost_history.append(costs)
            if len(self._reward_history) > self._reward_normalizer_window:
                self._reward_history.pop(0)
                self._cost_history.pop(0)
            
            # ì•ˆì •ì ì¸ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ percentile ê¸°ë°˜ ì •ê·œí™”
            reward_p95 = np.percentile(self._reward_history, 95)
            cost_p95 = np.percentile(self._cost_history, 95)
            
            if reward_p95 > 0 and cost_p95 > 0:
                normalized_rewards = rewards / reward_p95 * 5.0
                normalized_costs = costs / cost_p95 * 5.0
                raw_reward = normalized_rewards - normalized_costs
        
        # ìµœì¢… í´ë¦¬í•‘ ë° ì»¤ë¦¬í˜ëŸ¼ ë³´ë„ˆìŠ¤
        final_reward = np.clip(raw_reward, -10.0, 10.0)
        final_reward = final_reward * (1.0 + 0.1 * self.curriculum_factor)  # 10% ë³´ë„ˆìŠ¤
        
        return final_reward, reward_info
    
    def _get_obs(self):
        """48ì°¨ì› ê´€ì°° ê³µê°„ ìœ ì§€ - ì›ë³¸ê³¼ ë™ì¼"""
        dofs_position = self.data.qpos[7:].flatten() - self.model.key_qpos[0, 7:]
        
        velocity = self.data.qvel.flatten()
        base_linear_velocity = velocity[:3]
        base_angular_velocity = velocity[3:6]
        dofs_velocity = velocity[6:]
        
        desired_vel = self._desired_velocity
        last_action = self._last_action
        projected_gravity = self.projected_gravity
        
        curr_obs = np.concatenate(
            (
                base_linear_velocity * self._obs_scale["linear_velocity"],  # 3
                base_angular_velocity * self._obs_scale["angular_velocity"],  # 3
                projected_gravity,  # 3
                desired_vel * self._obs_scale["linear_velocity"],  # 3
                dofs_position * self._obs_scale["dofs_position"],  # 12
                dofs_velocity * self._obs_scale["dofs_velocity"],  # 12
                last_action,  # 12
            )
        ).clip(-self._clip_obs_threshold, self._clip_obs_threshold)
        
        return curr_obs  # ì´ 48ì°¨ì›
    
    def reset_model(self):
        qpos = self.model.key_qpos[0].copy()
        
        if random.random() < 0.5:
            qpos[7:] = self.BIPEDAL_READY_JOINTS
            qpos[2] = 0.60
            
            pitch_angle = np.deg2rad(-90)
            quat = np.array([
                np.cos(pitch_angle / 2),
                0,
                np.sin(pitch_angle / 2),
                0
            ])
            qpos[3:7] = quat
        
        if self._rand_power > 0.0:
            noise_scale = 0.05 + 0.05 * self.curriculum_factor
            joint_noise = np.random.normal(
                loc=0.0,
                scale=noise_scale * self._rand_power,
                size=qpos[7:].shape
            )
            qpos[7:] += joint_noise
            joint_limits = self.model.jnt_range[1:, :]
            qpos[7:] = np.clip(qpos[7:], joint_limits[:, 0], joint_limits[:, 1])
        
        self.data.qpos[:] = qpos
        self.data.ctrl[:] = qpos[7:].copy()
        
   
        vel_scale = min(1.0, 0.3 + 0.7 * self.curriculum_factor)
        self._desired_velocity = np.array([0.2 * vel_scale, 0, 0])
        
        self._step = 0
        self._last_action = np.zeros(12)
        self._feet_air_time = np.zeros(4)
        self._last_contacts = np.zeros(4)
        self._last_render_time = -1.0
        self._front_feet_touched = False
        self._last_feet_contact_forces = np.zeros(4)
        self._balance_history = []
        self._time_flipped_over = 0.0 #  íƒ€ì´ë¨¸ ì´ˆê¸°í™” ì¶”ê°€
        self._time_shoulder_below_pelvis = 0.0  # 8. ì–´ê¹¨-ê³¨ë°˜ ë†’ì´ íƒ€ì´ë¨¸ ì´ˆê¸°í™” 
        self._time_hip_on_ground = 0.0  # 9. hip ì ‘ì´‰ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        
        # âœ¨ [ì‹ ê·œ ì¶”ê°€] ì‹¤ì‹œê°„ ì €ì¥ì„ ìœ„í•œ ì—í”¼ì†Œë“œë³„ ë³€ìˆ˜ ì´ˆê¸°í™”
        self._current_episode_reward = 0.0
        self._current_episode_length = 0

        self._episode_count += 1
        
        observation = self._get_obs()
        return observation
    
    def _get_reset_info(self):
        return {
            "x_position": self.data.qpos[0],
            "y_position": self.data.qpos[1],
            "distance_from_origin": np.linalg.norm(self.data.qpos[0:2], ord=2),
            "episode_count": self._episode_count,
            "success_count": self._success_count,
            "success_rate": self._success_count / max(1, self._episode_count),
        }
    
    def _sample_desired_vel(self):
        desired_vel = np.random.default_rng().uniform(
            low=self._desired_velocity_min, high=self._desired_velocity_max
        )
        return desired_vel
    
    @staticmethod
    def euler_from_quaternion(w, x, y, z):
        t0 = +2.0 * (w * x + y * z)
        t1 = +1.0 - 2.0 * (x * x + y * y)
        roll_x = np.arctan2(t0, t1)
        
        t2 = +2.0 * (w * y - z * x)
        t2 = +1.0 if t2 > +1.0 else t2
        t2 = -1.0 if t2 < -1.0 else t2
        pitch_y = np.arcsin(t2)
        
        t3 = +2.0 * (w * z + x * y)
        t4 = +1.0 - 2.0 * (y * y + z * z)
        yaw_z = np.arctan2(t3, t4)
        
        return roll_x, pitch_y, yaw_z
    
    # âœ¨ [ì‹ ê·œ ì¶”ê°€] ì‹¤ì‹œê°„ ì €ì¥ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ ë©”ì„œë“œë“¤
    def get_detailed_episode_info(self):
        """ì—í”¼ì†Œë“œë³„ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì‹œê°„ ì €ì¥ìš©ì…ë‹ˆë‹¤."""
        try:
            # ê¸°ë³¸ ì—í”¼ì†Œë“œ ì •ë³´
            episode_info = {
                'episode_count': self._episode_count,
                'success_count': self._success_count,
                'success_rate': self._success_count / max(1, self._episode_count),
                'current_step': self._step,
                'max_episode_time': self._max_episode_time_sec,
                'time_remaining': max(0, self._max_episode_time_sec - self._step * self.dt),
            }
            
            # ë¡œë´‡ ìƒíƒœ ì •ë³´
            robot_state = {
                'position': {
                    'x': float(self.data.qpos[0]),
                    'y': float(self.data.qpos[1]),
                    'z': float(self.data.qpos[2]),
                    'distance_from_origin': float(np.linalg.norm(self.data.qpos[0:2], ord=2))
                },
                'orientation': {
                    'quaternion': self.data.qpos[3:7].tolist(),
                    'euler': self.euler_from_quaternion(*self.data.qpos[3:7]).tolist()
                },
                'velocity': {
                    'linear': self.data.qvel[:3].tolist(),
                    'angular': self.data.qvel[3:6].tolist(),
                    'joint': self.data.qvel[6:].tolist()
                },
                'joint_positions': self.data.qpos[7:].tolist(),
                'joint_velocities': self.data.qvel[6:].tolist(),
                'joint_accelerations': self.data.qacc[6:].tolist() if hasattr(self.data, 'qacc') else None,
            }
            
            # ë³´ìƒ ë° ë¹„ìš© ì •ë³´
            reward_info = {
                'current_episode_reward': getattr(self, '_current_episode_reward', 0.0),  # í˜„ì¬ ì—í”¼ì†Œë“œ ëˆ„ì  ë³´ìƒ
                'current_episode_length': getattr(self, '_current_episode_length', 0),    # í˜„ì¬ ì—í”¼ì†Œë“œ ê¸¸ì´
                'reward_weights': self.reward_weights.copy(),
                'cost_weights': self.cost_weights.copy(),
            }
            
            # í™˜ê²½ ì„¤ì • ì •ë³´
            env_config = {
                'ctrl_type': getattr(self, 'ctrl_type', 'unknown'),
                'biped': self.biped,
                'rand_power': self._rand_power,
                'action_noise_scale': self._action_noise_scale,
                'frame_skip': self.frame_skip,
                'dt': self.dt,
                'curriculum_factor': self.curriculum_factor,
                'desired_velocity': self._desired_velocity.tolist(),
                'healthy_z_range': self._healthy_z_range,
                'healthy_pitch_range': self._healthy_pitch_range,
                'healthy_roll_range': self._healthy_roll_range,
            }
            
            # ë°œ ì ‘ì´‰ ì •ë³´
            contact_info = {
                'feet_contact_forces': self.feet_contact_forces.tolist(),
                'front_feet_contact_forces': self.front_feet_contact_forces.tolist(),
                'feet_air_time': self._feet_air_time.tolist(),
                'last_contacts': self._last_contacts.tolist(),
            }
            
            # ì•ˆì •ì„± ë©”íŠ¸ë¦­
            stability_metrics = {
                'is_healthy': self.is_healthy,
                'is_flipped_over': self.is_flipped_over,
                'time_flipped_over': self._time_flipped_over,
                'is_shoulder_below_pelvis': self.is_shoulder_below_pelvis,
                'time_shoulder_below_pelvis': self._time_shoulder_below_pelvis,
                'is_hip_on_ground': self.is_hip_on_ground,
                'time_hip_on_ground': self._time_hip_on_ground,
                'shoulder_below_pelvis_cost': float(self.shoulder_below_pelvis_cost),
                'hip_ground_contact_cost': float(self.hip_ground_contact_cost),
                'trunk_up_alignment': float(self._trunk_up_alignment),
                'projected_gravity': self.projected_gravity.tolist(),
                'balance_history': self._balance_history.copy() if hasattr(self, '_balance_history') else [],
            }
            
            # ìµœê·¼ ì•¡ì…˜ ì •ë³´
            action_info = {
                'last_action': self._last_action.tolist(),
                'last_feet_contact_forces': self._last_feet_contact_forces.tolist(),
            }
            
            return {
                'episode_info': episode_info,
                'robot_state': robot_state,
                'reward_info': reward_info,
                'env_config': env_config,
                'contact_info': contact_info,
                'stability_metrics': stability_metrics,
                'action_info': action_info,
                'timestamp': time.time(),
                'simulation_time': self.data.time,
            }
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
            return {
                'episode_info': {
                    'episode_count': self._episode_count,
                    'success_count': self._success_count,
                    'error': str(e)
                },
                'timestamp': time.time(),
                'error': f"ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def get_environment_summary(self):
        """í™˜ê²½ì˜ ì „ì²´ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì‹œê°„ ì €ì¥ìš©ì…ë‹ˆë‹¤."""
        try:
            return {
                'environment_class': self.__class__.__name__,
                'model_path': str(getattr(self, 'model_path', 'unknown')),
                'observation_space': str(self.observation_space),
                'action_space': str(self.action_space),
                'metadata': self.metadata,
                'frame_skip': self.frame_skip,
                'dt': self.dt,
                'max_episode_time_sec': self._max_episode_time_sec,
                'reset_noise_scale': self._reset_noise_scale,
                'clip_obs_threshold': self._clip_obs_threshold,
                'max_balance_history': self._max_balance_history,
                'curriculum_base': self._curriculum_base,
                'tracking_velocity_sigma': self._tracking_velocity_sigma,
                'desired_velocity_min': self._desired_velocity_min.tolist(),
                'desired_velocity_max': self._desired_velocity_max.tolist(),
                'obs_scale': self._obs_scale,
                'gravity_vector': self._gravity_vector.tolist(),
                'default_joint_position': self._default_joint_position.tolist(),
                'bipedal_ready_joints': self.BIPEDAL_READY_JOINTS.tolist(),
                'feet_site_names': list(self._feet_site_name_to_id.keys()),
                'main_body_id': self._main_body_id,
                'cfrc_ext_feet_indices': self._cfrc_ext_feet_indices,
                'cfrc_ext_front_feet_indices': self._cfrc_ext_front_feet_indices,
                'cfrc_ext_contact_indices': self._cfrc_ext_contact_indices,
                'timestamp': time.time(),
            }
        except Exception as e:
            return {
                'environment_class': self.__class__.__name__,
                'error': f"í™˜ê²½ ìš”ì•½ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'timestamp': time.time(),
            }
    
    def get_performance_metrics(self):
        """í˜„ì¬ ì—í”¼ì†Œë“œì˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì‹œê°„ ì €ì¥ìš©ì…ë‹ˆë‹¤."""
        try:
            # ë³´ìƒ ì»´í¬ë„ŒíŠ¸ ê³„ì‚°
            reward_components = {}
            if hasattr(self, 'reward_weights'):
                for key in self.reward_weights:
                    if hasattr(self, key):
                        try:
                            reward_components[key] = float(getattr(self, key))
                        except:
                            reward_components[key] = 0.0
            
            # ë¹„ìš© ì»´í¬ë„ŒíŠ¸ ê³„ì‚°
            cost_components = {}
            if hasattr(self, 'cost_weights'):
                for key in self.cost_weights:
                    if hasattr(self, key):
                        try:
                            cost_components[key] = float(getattr(self, key))
                        except:
                            cost_components[key] = 0.0
            
            # ì•ˆì •ì„± ì ìˆ˜
            stability_score = 0.0
            if hasattr(self, '_balance_history') and self._balance_history:
                stability_score = float(np.mean(self._balance_history))
            
            # ì§„í–‰ë¥ 
            progress = min(1.0, self._step / (self._max_episode_time_sec / self.dt))
            
            return {
                'episode_progress': progress,
                'current_step': self._step,
                'max_steps': int(self._max_episode_time_sec / self.dt),
                'reward_components': reward_components,
                'cost_components': cost_components,
                'stability_score': stability_score,
                'is_healthy': self.is_healthy,
                'is_flipped_over': self.is_flipped_over,
                'time_flipped_over': self._time_flipped_over,
                'is_shoulder_below_pelvis': self.is_shoulder_below_pelvis,
                'time_shoulder_below_pelvis': self._time_shoulder_below_pelvis,
                'is_hip_on_ground': self.is_hip_on_ground,
                'time_hip_on_ground': self._time_hip_on_ground,
                'curriculum_factor': self.curriculum_factor,
                'timestamp': time.time(),
            }
        except Exception as e:
            return {
                'error': f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'timestamp': time.time(),
            }